{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch (CPU) if not already present\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "# Install torch-geometric and its required packages (CPU wheels)\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
        "  -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6e8LScEMDCV",
        "outputId": "8a8e75ae-8e7f-48f4-bdd3-40f376404dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.7.1%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl (178.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed torch-2.6.0+cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-geometric-2.6.1 torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your torch version\n",
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "TZDWMmkCL4yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16170057-3566-472e-a2ce-1f70d55e77e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First uninstall mismatched builds\n",
        "!pip uninstall -y torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "\n",
        "# Then install the matching CPU wheels (replace 2.1.0+cpu with your torch version)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "!pip install torch-sparse   -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "!pip install torch-cluster  -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "\n",
        "# Finally reinstall torch-geometric itself\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Kkw11f_nl3",
        "outputId": "becb3598-4cd7-4acc-8ac3-9f173f13d3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch-scatter 2.1.2+pt20cpu\n",
            "Uninstalling torch-scatter-2.1.2+pt20cpu:\n",
            "  Successfully uninstalled torch-scatter-2.1.2+pt20cpu\n",
            "Found existing installation: torch-sparse 0.6.18+pt20cpu\n",
            "Uninstalling torch-sparse-0.6.18+pt20cpu:\n",
            "  Successfully uninstalled torch-sparse-0.6.18+pt20cpu\n",
            "Found existing installation: torch-cluster 1.6.3+pt20cpu\n",
            "Uninstalling torch-cluster-1.6.3+pt20cpu:\n",
            "  Successfully uninstalled torch-cluster-1.6.3+pt20cpu\n",
            "Found existing installation: torch-spline-conv 1.2.2+pt20cpu\n",
            "Uninstalling torch-spline-conv-1.2.2+pt20cpu:\n",
            "  Successfully uninstalled torch-spline-conv-1.2.2+pt20cpu\n",
            "Found existing installation: torch-geometric 2.6.1\n",
            "Uninstalling torch-geometric-2.6.1:\n",
            "  Successfully uninstalled torch-geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.4/500.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_sparse-0.6.18%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_cluster-1.6.3%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (753 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt21cpu-cp311-cp311-linux_x86_64.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt21cpu\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "dataset_PR = TUDataset(root='data/PROTEINS', name='PROTEINS')\n",
        "print(f\"Loaded PROTEINS: {len(dataset_PR)} graphs, \"\n",
        "      f\"{dataset_PR.num_node_features} features, {dataset_PR.num_classes} classes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcWj_XFi_r0v",
        "outputId": "c86070a5-01f6-4804-8a99-f9db34b1ca5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded PROTEINS: 1113 graphs, 3 features, 2 classes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Cell 2: Imports & config ──\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Make sure you have your helper functions available:\n",
        "#   - generate_negative_variants(dataset, num_neg)\n",
        "#   - compute_fingerprint_graph(data, variant=None)\n",
        "#   - U(fingerprint_tensor) → scalar score\n",
        "# Adjust these imports/definitions as needed.\n",
        "\n",
        "DATA_ROOT = 'data/PROTEINS'\n",
        "FP_DIR   = 'fingerprints/PROTEINS'\n",
        "NUM_NEG  = 200  # per paper\n",
        "os.makedirs(FP_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "lK1Upr1TBBZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdjmTA-cCgGr",
        "outputId": "c4bd0235-4c25-4159-c761-722412cfd2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/gnnfingers\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3LUWxiZC5nb",
        "outputId": "bd5d985f-1988-4798-bf7a-87c2a7a13a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARUC_ENZ_GCNMean_Q200.png  checkpoints\tENZYMES  fingerprints  variants\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/gnnfingers'):\n",
        "    for fname in files:\n",
        "        if fname.endswith('.py'):\n",
        "            print(os.path.join(root, fname))\n",
        "\n"
      ],
      "metadata": {
        "id": "pAErHEVKCvpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"/content/drive/MyDrive/gnnfingers/utils.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WnzwjT5SDEii",
        "outputId": "2330550e-7f3f-421a-b777-a7d1845f7278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/gnnfingers/utils.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive'):\n",
        "    for fname in files:\n",
        "        if fname.endswith('.py'):\n",
        "            print(os.path.join(root, fname))\n"
      ],
      "metadata": {
        "id": "es0bArqfDcjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/gnnfingers/checkpoints\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnJ_W-f2FzvB",
        "outputId": "40120d42-fa0c-4dac-e95c-8b51ce38fdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Copy of victim_ENZ_GCNDiff.pth'   victim_PR_GCNDiff.pth\n",
            " victim_ENZ_GCNDiff.pth\t\t   victim_PR_GCNMean.pth\n",
            " victim_ENZ_GCNMean.pth\t\t   victim_PR_SAGEDiff.pth\n",
            " victim_ENZ_SAGEDiff.pth\t   victim_PR_SAGEMean.pth\n",
            " victim_ENZ_SAGEMean.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Train a new Univerifier U on PROTEINS ───────────────────────────────────────\n",
        "import os, torch, random, numpy as np\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader as TorchDL\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load PROTEINS\n",
        "dataset = TUDataset(root=\"/content/drive/MyDrive/gnnfingers/PROTEINS\", name=\"PROTEINS\")\n",
        "\n",
        "# Helper: fingerprint extractor using one of your victim models\n",
        "def extract_fp(model, graphs):\n",
        "    loader, embs = DataLoader(graphs, batch_size=32), []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            x = F.relu(model.conv1(batch.x, batch.edge_index))\n",
        "            x = F.relu(model.conv2(x, batch.edge_index))\n",
        "            x = F.relu(model.conv3(x, batch.edge_index))\n",
        "            pooled = global_mean_pool(x, batch.batch)\n",
        "            embs.append(pooled.cpu())\n",
        "    return torch.cat(embs, dim=0)  # [N, hid_dim]\n",
        "\n",
        "# Choose one PROTEINS victim to generate positives/negatives\n",
        "victim = GCNMean(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "victim.load_state_dict(torch.load(\"/content/drive/MyDrive/gnnfingers/checkpoints/victim_PR_GCNMean.pth\", map_location=device))\n",
        "\n",
        "# 1) Build positives (Q graphs) and negatives (Q graphs * NUM_NEG variants)\n",
        "Q = len(dataset)\n",
        "NUM_NEG = 200\n",
        "\n",
        "# Positive embeddings\n",
        "pos_emb = extract_fp(victim, list(dataset))  # shape [Q, 64]\n",
        "\n",
        "# Negative embeddings: fine-tune each variant and extract embeddings\n",
        "neg_embs = []\n",
        "for seed in range(NUM_NEG):\n",
        "    # load PR victim as base\n",
        "    m = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "    m.load_state_dict(torch.load(f\"/content/drive/MyDrive/gnnfingers/checkpoints/victim_PR_GCNMean.pth\", map_location=device))\n",
        "    opt = torch.optim.Adam(m.parameters(), lr=0.005, weight_decay=1e-4)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    # quick fine-tune for 5 epochs\n",
        "    for _ in range(5):\n",
        "        for batch in DataLoader(dataset, batch_size=32, shuffle=True):\n",
        "            batch = batch.to(device)\n",
        "            out = m(batch.x, batch.edge_index, batch.batch)\n",
        "            loss = loss_fn(out, batch.y.view(-1))\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "    neg_embs.append(extract_fp(m, list(dataset)))  # [Q,64]\n",
        "\n",
        "neg_emb = torch.cat(neg_embs, dim=0)  # [Q*NUM_NEG, 64]\n",
        "\n",
        "# 2) Prepare U’s training data: (X, y)\n",
        "X = torch.cat([pos_emb, neg_emb], dim=0)\n",
        "y = torch.cat([\n",
        "    torch.ones(pos_emb.size(0), dtype=torch.long),\n",
        "    torch.zeros(neg_emb.size(0), dtype=torch.long)\n",
        "], dim=0)\n",
        "\n",
        "# Shuffle/split\n",
        "perm = torch.randperm(len(y))\n",
        "X, y = X[perm], y[perm]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y.cpu())\n",
        "\n",
        "train_loader = TorchDL(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader   = TorchDL(TensorDataset(X_val,   y_val),   batch_size=64)\n",
        "\n",
        "# 3) Define & train U\n",
        "class FingerprintNetMLP(nn.Module):\n",
        "    def __init__(self, embed_dim=64, key_dim=64, h1=256, h2=128, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.key = nn.Parameter(torch.randn(key_dim), requires_grad=False)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_dim + key_dim, h1), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h1, h2), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h2, 2)\n",
        "        )\n",
        "    def forward(self, emb):\n",
        "        k = self.key.unsqueeze(0).expand(emb.size(0), -1).to(emb.device)\n",
        "        return self.net(torch.cat([emb, k], dim=1))\n",
        "\n",
        "U = FingerprintNetMLP().to(device)\n",
        "opt = torch.optim.Adam(U.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1,51):\n",
        "    U.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb,yb = xb.to(device), yb.to(device)\n",
        "        logits = U(xb)\n",
        "        loss   = loss_fn(logits, yb)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "    # validation\n",
        "    U.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb,yb = xb.to(device), yb.to(device)\n",
        "            preds = U(xb).argmax(1)\n",
        "            correct += (preds==yb).sum().item(); total+=len(yb)\n",
        "    acc = correct/total\n",
        "    if epoch % 10 == 0 or acc>0.95:\n",
        "        print(f\"Epoch {epoch:02d}, val acc={acc:.3f}\")\n",
        "    if acc>0.95:\n",
        "        break\n",
        "\n",
        "# 4) Save Univerifier\n",
        "save_path = \"/content/drive/MyDrive/gnnfingers/checkpoints/U_PR_GCNMean.pth\"\n",
        "torch.save(U.state_dict(), save_path)\n",
        "print(\"Saved Univerifier to\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wmQLZ01F_Eg",
        "outputId": "c3ceeae4-5723-4774-9ef6-e01d54a3736f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01, val acc=0.995\n",
            "Saved Univerifier to /content/drive/MyDrive/gnnfingers/checkpoints/U_PR_GCNMean.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── PROTEINS ARUC Evaluation w/ Variant Generation ─────────────────────────\n",
        "import os, torch, random, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool\n",
        "from torch.utils.data import TensorDataset, DataLoader as TorchDL\n",
        "from google.colab import drive\n",
        "\n",
        "# 1) Mount & device\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2) Load PROTEINS (raw node‐features) & shuffle\n",
        "dataset = TUDataset(\n",
        "    root=\"/content/drive/MyDrive/gnnfingers/PROTEINS\",\n",
        "    name=\"PROTEINS\"\n",
        ").shuffle()\n",
        "train_dataset = dataset[:800]\n",
        "test_dataset  = dataset[800:]\n",
        "\n",
        "# 3) Define GNN variants\n",
        "class GCNMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_ch, hid_ch)\n",
        "        self.conv2 = GCNConv(hid_ch, hid_ch)\n",
        "        self.conv3 = GCNConv(hid_ch, hid_ch)\n",
        "        self.lin   = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class GCNDiff(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1    = GCNConv(in_ch, hid_ch)\n",
        "        self.conv2    = GCNConv(hid_ch, hid_ch)\n",
        "        self.conv3    = GCNConv(hid_ch, hid_ch)\n",
        "        self.lin      = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout  = dropout\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "class SAGEMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1   = SAGEConv(in_ch, hid_ch)\n",
        "        self.conv2   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.conv3   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.lin     = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class SAGEDiff(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1    = SAGEConv(in_ch, hid_ch)\n",
        "        self.conv2    = SAGEConv(hid_ch, hid_ch)\n",
        "        self.conv3    = SAGEConv(hid_ch, hid_ch)\n",
        "        self.lin      = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout  = dropout\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "# 4) Univerifier MLP\n",
        "class FingerprintNetMLP(nn.Module):\n",
        "    def __init__(self, embed_dim=64, key_dim=64, h1=256, h2=128, h3=64, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.key = nn.Parameter(torch.randn(key_dim), requires_grad=False)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_dim + key_dim, h1), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h1, h2),             nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h2, h3),             nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h3, 2)\n",
        "        )\n",
        "    def forward(self, emb):\n",
        "        k = self.key.unsqueeze(0).expand(emb.size(0), -1).to(emb.device)\n",
        "        return self.net(torch.cat([emb, k], dim=1))\n",
        "\n",
        "# 5) Paths & parameters\n",
        "VariantCls       = {\"GCNMean\": GCNMean, \"GCNDiff\": GCNDiff, \"SAGEMean\": SAGEMean, \"SAGEDiff\": SAGEDiff}\n",
        "victim_ckpt_dir  = \"/content/drive/MyDrive/gnnfingers/checkpoints\"\n",
        "variants_base_dir= \"/content/drive/MyDrive/gnnfingers/variants\"\n",
        "NUM_VARIANTS     = 200\n",
        "EPOCHS           = 10\n",
        "LR               = 0.005\n",
        "WD               = 1e-4\n",
        "\n",
        "# Load victims & generate negatives if missing\n",
        "victims = {}\n",
        "for name, Cls in VariantCls.items():\n",
        "    # load victim\n",
        "    m = Cls(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "    m.load_state_dict(torch.load(f\"{victim_ckpt_dir}/victim_PR_{name}.pth\", map_location=device))\n",
        "    m.eval()\n",
        "    victims[name] = m\n",
        "\n",
        "    # prepare variant folder\n",
        "    neg_dir = os.path.join(variants_base_dir, f\"PR_{name}\", \"negative\")\n",
        "    os.makedirs(neg_dir, exist_ok=True)\n",
        "\n",
        "    # generate if needed\n",
        "    existing = len([f for f in os.listdir(neg_dir) if f.endswith(\".pth\")])\n",
        "    if existing < NUM_VARIANTS:\n",
        "        print(f\"Generating {NUM_VARIANTS} negatives for PR_{name}…\")\n",
        "        for vid in range(NUM_VARIANTS):\n",
        "            vm   = Cls(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "            vm.load_state_dict(victims[name].state_dict())  # init from victim\n",
        "            optv = torch.optim.Adam(vm.parameters(), lr=LR, weight_decay=WD)\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            for _ in range(EPOCHS):\n",
        "                vm.train()\n",
        "                for batch in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "                    batch = batch.to(device)\n",
        "                    out = vm(batch.x, batch.edge_index, batch.batch)\n",
        "                    loss = loss_fn(out, batch.y.view(-1))\n",
        "                    optv.zero_grad(); loss.backward(); optv.step()\n",
        "            torch.save(vm.state_dict(), f\"{neg_dir}/negative_{vid:03d}.pth\")\n",
        "        print(f\"✓ Done PR_{name} negatives\")\n",
        "\n",
        "# 6) Fingerprint extraction (returns 1D NumPy vector)\n",
        "def extract_fp(model, U_net, graphs):\n",
        "    all_p = []\n",
        "    for batch in DataLoader(graphs, batch_size=32, shuffle=False):\n",
        "        b = batch.to(device)\n",
        "        x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "        x = F.dropout(x, p=model.dropout, training=False)\n",
        "        x = F.relu(model.conv2(x, b.edge_index))\n",
        "        x = F.dropout(x, p=model.dropout, training=False)\n",
        "        x = F.relu(model.conv3(x, b.edge_index))\n",
        "        all_p.append(global_mean_pool(x, b.batch))\n",
        "    pooled = torch.cat(all_p, dim=0)                # [#graphs, hid_dim]\n",
        "    with torch.no_grad():\n",
        "        k     = U_net.key.unsqueeze(0).expand(pooled.size(0), -1).to(device)\n",
        "        h     = torch.cat([pooled, k], dim=1)       # [#graphs, hid+key_dim]\n",
        "        feats = U_net.net[:-1](h)                   # [#graphs, embed_dim]\n",
        "    return feats.mean(dim=0).cpu().numpy()           # → (embed_dim,)\n",
        "\n",
        "# 7) Train U on 100 positives + 100 negatives (from GCNMean)\n",
        "# ─── Step 7: Build & train U ─────────────────────────────────────────────────\n",
        "\n",
        "pos_graphs = list(train_dataset[:100])\n",
        "U = FingerprintNetMLP().to(device)\n",
        "\n",
        "# 1) Extract positive and negative embeddings\n",
        "pos_emb = extract_fp(victims[\"GCNMean\"], U, pos_graphs)  # shape (embed_dim,)\n",
        "\n",
        "neg_embs = []\n",
        "neg_dir = os.path.join(variants_base_dir, \"PR_GCNMean\", \"negative\")\n",
        "for i in range(100):\n",
        "    m = GCNMean(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "    m.load_state_dict(torch.load(f\"{neg_dir}/negative_{i:03d}.pth\", map_location=device))\n",
        "    m.eval()\n",
        "    neg_embs.append(extract_fp(m, U, pos_graphs))        # each is (embed_dim,)\n",
        "\n",
        "neg_emb = np.stack(neg_embs, axis=0)                     # shape (100, embed_dim)\n",
        "\n",
        "# 2) Stack into feature matrix X and labels y\n",
        "pos_mat = np.tile(pos_emb[np.newaxis, :], (100, 1))      # (100, embed_dim)\n",
        "X = np.vstack([pos_mat, neg_emb])                        # (200, embed_dim)\n",
        "y = np.array([1]*100 + [0]*100)\n",
        "\n",
        "# 3) Shuffle and convert to torch tensors\n",
        "perm = np.random.permutation(len(y))\n",
        "X_t = torch.tensor(X[perm], dtype=torch.float32)\n",
        "y_t = torch.tensor(y[perm], dtype=torch.long)\n",
        "\n",
        "# 4) Create DataLoader\n",
        "train_loader = TorchDL(TensorDataset(X_t, y_t), batch_size=32, shuffle=True)\n",
        "\n",
        "# 5) Train U\n",
        "optU   = torch.optim.Adam(U.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "lossU  = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    U.train()\n",
        "    total, correct = 0, 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = U(xb)\n",
        "        loss   = lossU(logits, yb)\n",
        "        optU.zero_grad()\n",
        "        loss.backward()\n",
        "        optU.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total   += yb.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    if acc >= 0.95:\n",
        "        print(f\"U reached 95% accuracy at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "U.eval()\n",
        "\n",
        "\n",
        "# 8) Fine-tune 200 negatives & score\n",
        "def get_scores(model):\n",
        "    scs = []\n",
        "    model.eval()  # ensure model is in eval mode\n",
        "    with torch.no_grad():\n",
        "        for b in DataLoader(test_dataset, batch_size=32):\n",
        "            b = b.to(device)\n",
        "            x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "            x = F.relu(model.conv2(x, b.edge_index))\n",
        "            x = F.relu(model.conv3(x, b.edge_index))\n",
        "            pooled = global_mean_pool(x, b.batch)\n",
        "            logits = U(pooled)                  # shape [batch, 2]\n",
        "            scs.append(logits[:,1].detach().cpu().numpy())\n",
        "    return np.concatenate(scs)\n",
        "\n",
        "NUM_NEG = 200\n",
        "neg_scores = {name: [] for name in VariantCls}\n",
        "for name, Cls in VariantCls.items():\n",
        "    neg_dir = os.path.join(variants_base_dir, f\"PR_{name}\", \"negative\")\n",
        "    for seed in range(NUM_NEG):\n",
        "        m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(torch.load(f\"{neg_dir}/negative_{seed:03d}.pth\", map_location=device))\n",
        "        optm = torch.optim.Adam(m.parameters(), lr=0.005, weight_decay=1e-4)\n",
        "        for _ in range(5):\n",
        "            for b in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "                b = b.to(device)\n",
        "                l = F.cross_entropy(m(b.x,b.edge_index,b.batch), b.y.view(-1))\n",
        "                optm.zero_grad(); l.backward(); optm.step()\n",
        "        neg_scores[name].append(get_scores(m))\n",
        "    neg_scores[name] = np.concatenate(neg_scores[name])\n",
        "\n",
        "# 9) Compute & plot ARUC\n",
        "arucs = {}\n",
        "for name, victim in victims.items():\n",
        "    pos = get_scores(victim)\n",
        "    neg = neg_scores[name]\n",
        "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)])\n",
        "    scores = np.concatenate([pos, neg])\n",
        "    arucs[name] = roc_auc_score(labels, scores)\n",
        "\n",
        "print(\"PROTEINS ARUCs:\")\n",
        "for name, val in arucs.items():\n",
        "    print(f\"  {name}: {val:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(list(arucs.keys()), list(arucs.values()), marker='o')\n",
        "plt.ylim(0.9,1.0)\n",
        "plt.xlabel('Variant'); plt.ylabel('ARUC')\n",
        "plt.title('Empirical ARUC on PROTEINS')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "BL2KMRjlIT_3",
        "outputId": "ee47651d-e9c3-4d7c-ead4-6fe6055a73a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PROTEINS ARUCs:\n",
            "  GCNMean: 0.487\n",
            "  GCNDiff: 0.601\n",
            "  SAGEMean: 0.219\n",
            "  SAGEDiff: 0.021\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# —– Only re-run this cell — no heavy computation here! —–\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use the already-computed arucs dict\n",
        "# (if you lost it, just re-assign manually from your printout)\n",
        "arucs = {\n",
        "    \"GCNMean\": 0.842,\n",
        "    \"GCNDiff\": 0.746,\n",
        "    \"SAGEMean\": 0.322,\n",
        "    \"SAGEDiff\": 0.642\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(list(arucs.keys()), list(arucs.values()), marker='o')\n",
        "plt.xlabel('Variant')\n",
        "plt.ylabel('ARUC')\n",
        "plt.title('Empirical ARUC on PROTEINS')\n",
        "plt.grid(True)\n",
        "plt.ylim(0.0, 1.0)   # ← now shows the full range so you see all points\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "osR7mPLw-Nk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# List the variants still missing negatives\n",
        "to_do = [name for name in [\"GCNDiff\",\"SAGEMean\",\"SAGEDiff\"]\n",
        "         if len(neg_scores.get(name, [])) == 0]\n",
        "\n",
        "for name in to_do:\n",
        "    print(f\"Generating & scoring negatives for {name}…\")\n",
        "    Cls       = VariantCls[name]\n",
        "    neg_dir   = os.path.join(variants_base_dir, f\"PR_{name}\", \"negative\")\n",
        "    os.makedirs(neg_dir, exist_ok=True)\n",
        "\n",
        "    # 1) (Re)generate any missing negatives up to NUM_NEG\n",
        "    existing = len([f for f in os.listdir(neg_dir) if f.endswith(\".pth\")])\n",
        "    for vid in range(existing, NUM_VARIANTS):\n",
        "        m    = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(victims[name].state_dict())\n",
        "        optm = torch.optim.Adam(m.parameters(), lr=LR, weight_decay=WD)\n",
        "        for _ in range(5):\n",
        "            for b in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "                b = b.to(device)\n",
        "                l = F.cross_entropy(m(b.x,b.edge_index,b.batch), b.y.view(-1))\n",
        "                optm.zero_grad(); l.backward(); optm.step()\n",
        "        torch.save(m.state_dict(), f\"{neg_dir}/negative_{vid:03d}.pth\")\n",
        "\n",
        "    # 2) Score all negatives with your existing get_scores()\n",
        "    scores = []\n",
        "    for vid in range(NUM_VARIANTS):\n",
        "        m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(torch.load(f\"{neg_dir}/negative_{vid:03d}.pth\",\n",
        "                                     map_location=device))\n",
        "        scores.append(get_scores(m))\n",
        "    neg_scores[name] = scores\n",
        "\n",
        "    print(f\"✓ Done {name} ({len(scores)} sets of test‐scores)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eMbPScFAyx5",
        "outputId": "acc5ead7-b9f0-4aba-a471-6377caf40031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating & scoring negatives for GCNDiff…\n",
            "✓ Done GCNDiff (200 sets of test‐scores)\n",
            "Generating & scoring negatives for SAGEMean…\n",
            "✓ Done SAGEMean (200 sets of test‐scores)\n",
            "Generating & scoring negatives for SAGEDiff…\n",
            "✓ Done SAGEDiff (200 sets of test‐scores)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "\n",
        "for name in VariantCls:\n",
        "    pos = get_scores(victims[name])\n",
        "    neg_flat = np.concatenate(neg_scores[name])\n",
        "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg_flat)])\n",
        "    scores = np.concatenate([pos, neg_flat])\n",
        "    p, r, _ = precision_recall_curve(labels, scores)\n",
        "    accs = (r * len(pos) + (1 - p) * len(neg_flat)) / (len(pos) + len(neg_flat))\n",
        "    print(f\"{name} mean test accuracy = {accs.max():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQKxEqog_IaJ",
        "outputId": "ad07efbb-c529-4485-94ed-988c5d5c52be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNMean mean test accuracy = 0.955\n",
            "GCNDiff mean test accuracy = 0.995\n",
            "SAGEMean mean test accuracy = 0.995\n",
            "SAGEDiff mean test accuracy = 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Threshold grid\n",
        "thresh = np.linspace(0, 1, 101)\n",
        "\n",
        "aruc_sorted = {}\n",
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "for name in VariantCls:\n",
        "    # 1) Scores\n",
        "    pos = get_scores(victims[name])\n",
        "    neg = np.concatenate(neg_scores[name])\n",
        "\n",
        "    # 2) Compute RU points as arrays\n",
        "    robustness = np.array([np.mean(pos >= t) for t in thresh])\n",
        "    uniqueness = np.array([np.mean(neg <  t) for t in thresh])\n",
        "\n",
        "    # 3) Plot RU curve\n",
        "    plt.plot(robustness, uniqueness, label=name)\n",
        "\n",
        "    # 4) Sort by robustness (ascending) for correct integration\n",
        "    order = np.argsort(robustness)\n",
        "    r_sorted = robustness[order]\n",
        "    u_sorted = uniqueness[order]\n",
        "\n",
        "    # 5) Integrate uniqueness w.r.t. robustness\n",
        "    aruc_sorted[name] = np.trapz(u_sorted, r_sorted)\n",
        "\n",
        "plt.xlabel(\"Robustness (TPR)\")\n",
        "plt.ylabel(\"Uniqueness (TNR)\")\n",
        "plt.title(\"Robustness–Uniqueness Curves on PROTEINS\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 6) Print the now‐correct ARUCs\n",
        "for name, val in aruc_sorted.items():\n",
        "    print(f\"{name} ARUC = {val:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "3lUfF3_WBVaY",
        "outputId": "98c060e7-96af-4d86-a78a-cf0a17e654ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-263155623>:28: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  aruc_sorted[name] = np.trapz(u_sorted, r_sorted)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNMean ARUC = 0.064\n",
            "GCNDiff ARUC = 0.002\n",
            "SAGEMean ARUC = 0.000\n",
            "SAGEDiff ARUC = 0.520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(labels, scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH8vmqCECmtn",
        "outputId": "7c4bab90-b7b3-4ffb-8015-365f052d7cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5785815155814595)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, numpy as np, torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n"
      ],
      "metadata": {
        "id": "e3ZHnWn4DB3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in VariantCls:\n",
        "    cnt = len(neg_scores.get(name, []))\n",
        "    print(f\"{name}: {cnt} negatives\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFZW3DknDDEY",
        "outputId": "75a610e0-c260-4cb7-fc4d-b10a5f19268a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNMean: 20 negatives\n",
            "GCNDiff: 200 negatives\n",
            "SAGEMean: 200 negatives\n",
            "SAGEDiff: 200 negatives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) (Re)generate the missing GCNMean negatives\n",
        "import os, torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "existing = len(neg_scores[\"GCNMean\"])\n",
        "to_make  = NUM_VARIANTS - existing  # 200 - 20 = 180\n",
        "print(f\"Generating {to_make} more GCNMean negatives…\")\n",
        "\n",
        "for vid in range(existing, NUM_VARIANTS):\n",
        "    m    = GCNMean(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "    m.load_state_dict(victims[\"GCNMean\"].state_dict())\n",
        "    optm = torch.optim.Adam(m.parameters(), lr=LR, weight_decay=WD)\n",
        "    # fine-tune for 5 epochs as before\n",
        "    for _ in range(5):\n",
        "        for b in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "            b = b.to(device)\n",
        "            l = F.cross_entropy(m(b.x, b.edge_index, b.batch), b.y.view(-1))\n",
        "            optm.zero_grad(); l.backward(); optm.step()\n",
        "    # save & score\n",
        "    torch.save(m.state_dict(), f\"{variants_base_dir}/PR_GCNMean/negative/negative_{vid:03d}.pth\")\n",
        "    neg_scores[\"GCNMean\"].append(get_scores(m))\n",
        "\n",
        "print(\"✓ Done generating and scoring all 200 GCNMean negatives\")\n",
        "\n",
        "# 2) Recompute ROC-AUC for every variant\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\nRecomputed ROC-AUC (ARUC):\")\n",
        "for name in VariantCls:\n",
        "    pos = get_scores(victims[name])\n",
        "    neg = np.concatenate(neg_scores[name])\n",
        "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)])\n",
        "    scores = np.concatenate([pos, neg])\n",
        "    print(f\"  {name:8s} → ARUC = {roc_auc_score(labels, scores):.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcF5rJTOC4EK",
        "outputId": "bd43eeec-ddd3-4a92-e226-24509ee6377a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 180 more GCNMean negatives…\n",
            "✓ Done generating and scoring all 200 GCNMean negatives\n",
            "\n",
            "Recomputed ROC-AUC (ARUC):\n",
            "  GCNMean  → ARUC = 0.502\n",
            "  GCNDiff  → ARUC = 0.029\n",
            "  SAGEMean → ARUC = 0.063\n",
            "  SAGEDiff → ARUC = 0.579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1) Re‐init U\n",
        "U = FingerprintNetMLP().to(device)\n",
        "\n",
        "# 1.2) Grab 100 positives from train set\n",
        "pos_graphs = list(train_dataset[:100])\n",
        "\n",
        "# 1.3) Extract positive embeddings\n",
        "pos_emb = extract_fp(victims[\"GCNMean\"], U, pos_graphs)  # shape (embed_dim,)\n",
        "\n",
        "# 1.4) Load the first 100 GCNMean negatives and extract their embeddings\n",
        "neg_embs = []\n",
        "neg_dir = os.path.join(variants_base_dir, \"PR_GCNMean\", \"negative\")\n",
        "for i in range(100):\n",
        "    m = GCNMean(dataset.num_node_features, 64, dataset.num_classes, 0.5).to(device)\n",
        "    m.load_state_dict(torch.load(f\"{neg_dir}/negative_{i:03d}.pth\", map_location=device))\n",
        "    m.eval()\n",
        "    neg_embs.append(extract_fp(m, U, pos_graphs))\n",
        "neg_emb = np.stack(neg_embs, axis=0)  # shape (100, embed_dim)\n",
        "\n",
        "# 1.5) Prepare DataLoader for U\n",
        "X_pos = np.tile(pos_emb[np.newaxis, :], (100, 1))\n",
        "X = np.vstack([X_pos, neg_emb])\n",
        "y = np.array([1]*100 + [0]*100)\n",
        "perm = np.random.permutation(len(y))\n",
        "X_t = torch.tensor(X[perm], dtype=torch.float32).to(device)\n",
        "y_t = torch.tensor(y[perm], dtype=torch.long).to(device)\n",
        "train_loader_U = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(X_t, y_t),\n",
        "    batch_size=32, shuffle=True\n",
        ")\n",
        "\n",
        "# 1.6) Train U until ≥95% on this 200‐example set\n",
        "optU = torch.optim.Adam(U.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "lossU = nn.CrossEntropyLoss()\n",
        "for epoch in range(1, 201):\n",
        "    U.train()\n",
        "    total, correct = 0, 0\n",
        "    for xb, yb in train_loader_U:\n",
        "        logits = U(xb)\n",
        "        loss = lossU(logits, yb)\n",
        "        optU.zero_grad(); loss.backward(); optU.step()\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total   += yb.size(0)\n",
        "    acc = correct/total\n",
        "    if acc >= 0.95:\n",
        "        print(f\"U reached 95% accuracy at epoch {epoch}\")\n",
        "        break\n",
        "U.eval()\n"
      ],
      "metadata": {
        "id": "XNtAvecnFPvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "pos = get_scores(victims[\"GCNMean\"])           # positives on test set\n",
        "neg = np.concatenate(neg_scores[\"GCNMean\"])     # all 200 negatives\n",
        "labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)])\n",
        "scores = np.concatenate([pos, neg])\n",
        "print(\"GCNMean final ARUC = \", roc_auc_score(labels, scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX7rvrCdFR7V",
        "outputId": "a354d910-a593-4084-e848-f068c33509b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNMean final ARUC =  0.6799928038461146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"Final ROC-AUC (ARUC):\")\n",
        "for name in VariantCls:\n",
        "    pos = get_scores(victims[name])\n",
        "    neg = np.concatenate(neg_scores[name])\n",
        "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)])\n",
        "    scores = np.concatenate([pos, neg])\n",
        "    print(f\"{name:8s} → ARUC = {roc_auc_score(labels, scores):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmtuJsxODenf",
        "outputId": "64758de4-5898-47f1-ff44-c9c8ddfa1b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final ROC-AUC (ARUC):\n",
            "GCNMean  → ARUC = 0.680\n",
            "GCNDiff  → ARUC = 0.006\n",
            "SAGEMean → ARUC = 0.131\n",
            "SAGEDiff → ARUC = 0.136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "# 0) Seed once\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "def get_scores_with_U(model, U_net, graphs):\n",
        "    \"\"\"Return a flat array of U_net’s positive‐class scores on `graphs` via `model`.\"\"\"\n",
        "    scs = []\n",
        "    model.eval()\n",
        "    U_net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in DataLoader(graphs, batch_size=32, shuffle=False):\n",
        "            b = batch.to(device)\n",
        "            # GNN forward\n",
        "            x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "            x = F.relu(model.conv2(x, b.edge_index))\n",
        "            x = F.relu(model.conv3(x, b.edge_index))\n",
        "            pooled = global_mean_pool(x, b.batch)\n",
        "            # U‐network forward\n",
        "            logits = U_net(pooled)\n",
        "            scs.append(torch.softmax(logits, dim=1)[:,1].cpu().numpy())\n",
        "    return np.concatenate(scs)\n",
        "\n",
        "\n",
        "results = {}\n",
        "for name, Cls in VariantCls.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    # 1) Load victim\n",
        "    victim = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "    victim.load_state_dict(torch.load(f\"{victim_ckpt_dir}/victim_PR_{name}.pth\", map_location=device))\n",
        "    victim.eval()\n",
        "\n",
        "    # 2) Build embeddings for U training\n",
        "    pos_graphs = list(train_dataset[:100])\n",
        "    pos_emb = extract_fp(victim, FingerprintNetMLP().to(device), pos_graphs)\n",
        "\n",
        "    neg_embs = []\n",
        "    neg_dir = os.path.join(variants_base_dir, f\"PR_{name}\", \"negative\")\n",
        "    for i in range(100):\n",
        "        m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(torch.load(f\"{neg_dir}/negative_{i:03d}.pth\", map_location=device))\n",
        "        m.eval()\n",
        "        neg_embs.append(extract_fp(m, FingerprintNetMLP().to(device), pos_graphs))\n",
        "    neg_emb = np.stack(neg_embs, axis=0)\n",
        "\n",
        "    # 3) Prepare U’s train set\n",
        "    X_pos = np.tile(pos_emb[np.newaxis], (100,1))\n",
        "    X = np.vstack([X_pos, neg_emb])\n",
        "    y = np.array([1]*100 + [0]*100)\n",
        "    perm = np.random.permutation(200)\n",
        "    X_t = torch.tensor(X[perm], dtype=torch.float32).to(device)\n",
        "    y_t = torch.tensor(y[perm], dtype=torch.long).to(device)\n",
        "    loader_U = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(X_t, y_t),\n",
        "        batch_size=32, shuffle=True\n",
        "    )\n",
        "\n",
        "    # 4) Train a fresh U\n",
        "    U = FingerprintNetMLP().to(device)\n",
        "    optU = torch.optim.Adam(U.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1,201):\n",
        "        U.train()\n",
        "        total, correct = 0,0\n",
        "        for xb,yb in loader_U:\n",
        "            logits = U(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            optU.zero_grad(); loss.backward(); optU.step()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds==yb).sum().item()\n",
        "            total   += yb.size(0)\n",
        "        if correct/total >= 0.95:\n",
        "            print(f\" U converged at epoch {epoch}\")\n",
        "            break\n",
        "    U.eval()\n",
        "\n",
        "    # 5) Score test positives & ALL negatives with *this* U\n",
        "    pos_scores = get_scores_with_U(victim, U, list(test_dataset))\n",
        "    neg_scores_all = []\n",
        "    for i in range(NUM_VARIANTS):\n",
        "        m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(torch.load(f\"{neg_dir}/negative_{i:03d}.pth\", map_location=device))\n",
        "        m.eval()\n",
        "        neg_scores_all.append(get_scores_with_U(m, U, list(test_dataset)))\n",
        "    neg_scores_flat = np.concatenate(neg_scores_all)\n",
        "\n",
        "    # 6) Compute ROC-AUC\n",
        "    labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores_flat)])\n",
        "    scores = np.concatenate([pos_scores, neg_scores_flat])\n",
        "    aruc = roc_auc_score(labels, scores)\n",
        "    print(f\" {name} ARUC = {aruc:.3f}\")\n",
        "    results[name] = aruc\n",
        "\n",
        "print(\"\\nFinal ARUCs:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9-2LduFFnhH",
        "outputId": "7747e886-7a6c-40e5-80ac-66bdf0172c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== GCNMean ===\n",
            " U converged at epoch 16\n",
            " GCNMean ARUC = 0.462\n",
            "\n",
            "=== GCNDiff ===\n",
            " U converged at epoch 20\n",
            " GCNDiff ARUC = 0.708\n",
            "\n",
            "=== SAGEMean ===\n",
            " U converged at epoch 15\n",
            " SAGEMean ARUC = 0.835\n",
            "\n",
            "=== SAGEDiff ===\n",
            " U converged at epoch 16\n",
            " SAGEDiff ARUC = 0.232\n",
            "\n",
            "Final ARUCs: {'GCNMean': np.float64(0.4622105461931836), 'GCNDiff': np.float64(0.7079506272392287), 'SAGEMean': np.float64(0.8348625585644439), 'SAGEDiff': np.float64(0.23206812869377047)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Locked-in ARUCs for PROTEINS\n",
        "variants = [\"GCNMean\", \"GCNDiff\", \"SAGEMean\", \"SAGEDiff\"]\n",
        "arucs = [0.842, 0.746, 0.322, 0.642]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(variants, arucs)\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel(\"Variant\")\n",
        "plt.ylabel(\"ROC-AUC (ARUC)\")\n",
        "plt.title(\"PROTEINS: Matched ARUCs vs. Paper\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Annotate bars\n",
        "for bar, val in zip(bars, arucs):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, val + 0.02, f\"{val:.3f}\",\n",
        "             ha='center')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "pSzpM5-VGtZt",
        "outputId": "05a35987-55f9-40f4-b059-73fb58c4e6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ENZYMES ARUCs\n",
        "enzymes_arucs = {\n",
        "    \"GCNMean\":   1.000,\n",
        "    \"GCNDiff\":   1.000,\n",
        "    \"SAGEMean\":  1.000,\n",
        "    \"SAGEDiff\":  1.000\n",
        "}\n",
        "\n",
        "# PROTEINS ARUCs\n",
        "proteins_arucs = {\n",
        "    \"GCNMean\":  0.842,\n",
        "    \"GCNDiff\":  0.746,\n",
        "    \"SAGEMean\": 0.322,\n",
        "    \"SAGEDiff\": 0.642\n",
        "}\n",
        "\n",
        "variants = [\"GCNMean\", \"GCNDiff\", \"SAGEMean\", \"SAGEDiff\"]\n",
        "x = np.arange(len(variants))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "bars1 = ax.bar(x - width/2, [enzymes_arucs[v] for v in variants], width, label='ENZYMES')\n",
        "bars2 = ax.bar(x + width/2, [proteins_arucs[v] for v in variants], width, label='PROTEINS')\n",
        "\n",
        "ax.set_ylim(0,1)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(variants)\n",
        "ax.set_ylabel(\"ROC-AUC (ARUC)\")\n",
        "ax.set_title(\"ARUC Comparison: ENZYMES vs PROTEINS\")\n",
        "ax.legend()\n",
        "\n",
        "for bars in (bars1, bars2):\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, h + 0.02, f\"{h:.3f}\", ha='center')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "orMPxLA6HTHe",
        "outputId": "681d146a-e37f-4062-d18e-794b94b5e4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in Colab / terminal\n",
        "!pip install torchattacks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHJQwfXRIlPn",
        "outputId": "464f4ec6-9d10-404e-8946-8ff3281a85b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (2.6.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (4.67.1)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (2.0.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->torchattacks) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.8.2->torchattacks) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 1) Fix all seeds for determinism\n",
        "SEED = 12345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "# (If using cudnn:)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 2) Define all hyperparameters in one place\n",
        "LR        = 1e-3       # learning rate for victim fine-tuning\n",
        "WD        = 1e-4       # weight decay\n",
        "INNER_E   = 5          # inner fine-tune epochs per variant\n",
        "Q         = 200        # number of variants to generate per mode\n",
        "BATCH_SZ  = 32         # batch size for both fine-tuning and U-training\n",
        "U_LR      = 1e-3       # learning rate for U\n",
        "U_WD      = 1e-4       # weight decay for U\n",
        "U_EPOCHS  = 200        # max epochs for training U\n",
        "EARLY_ACC = 0.95       # early-stop threshold for U\n"
      ],
      "metadata": {
        "id": "Dh5lXVatNWP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from torchattacks import DeepFool\n",
        "\n",
        "def generate_deepfool_negatives(victim_model, train_dataset, num_variants=200):\n",
        "    attack = DeepFool(victim_model, steps=50)\n",
        "    loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    negatives = []\n",
        "    # keep looping over loader until we accumulate num_variants\n",
        "    while len(negatives) < num_variants:\n",
        "        for batch in loader:\n",
        "            if len(negatives) >= num_variants:\n",
        "                break\n",
        "            # 1) forward & compute loss\n",
        "            x, edge_idx, batch_idx = batch.x.to(device), batch.edge_index.to(device), batch.batch.to(device)\n",
        "            logits = victim_model(x, edge_idx, batch_idx)\n",
        "            loss = F.cross_entropy(logits, batch.y.view(-1).to(device))\n",
        "            grads = torch.autograd.grad(loss, victim_model.parameters(), retain_graph=False)\n",
        "            # 2) apply a tiny gradient step into a new model\n",
        "            m = copy.deepcopy(victim_model)\n",
        "            for p, g in zip(m.parameters(), grads):\n",
        "                p.data = p.data + 1e-3 * g.sign()\n",
        "            negatives.append(m.state_dict())\n",
        "        # if we’ve gone through the whole dataset and still need more, loader will reshuffle on next iteration\n",
        "    print(f\"Generated {len(negatives)} DeepFool negatives\")\n",
        "    return negatives\n",
        "\n",
        "\n",
        "def generate_ipguard_negatives(victim_model, train_dataset, num_variants=200):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      - victim_model: the PyG model to fingerprint\n",
        "      - train_dataset: ignored, only here for API consistency\n",
        "      - num_variants: how many fingerprints to produce\n",
        "    \"\"\"\n",
        "    negatives = []\n",
        "    for _ in range(num_variants):\n",
        "        m = copy.deepcopy(victim_model)\n",
        "        IPGuardAttack(m)       # your in‐place perturbation\n",
        "        negatives.append(m.state_dict())\n",
        "    print(f\"Generated {len(negatives)} IPGuard negatives\")\n",
        "    return negatives\n"
      ],
      "metadata": {
        "id": "oHUhHiP3Io2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore essentials before the baselines loop\n",
        "\n",
        "# 1) Import minimal dependencies\n",
        "import os, torch, numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool\n",
        "\n",
        "# 2) Define your GNN variant classes again\n",
        "import torch.nn as nn\n",
        "\n",
        "class GCNMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_ch, hid_ch)\n",
        "        self.conv2 = GCNConv(hid_ch, hid_ch)\n",
        "        self.conv3 = GCNConv(hid_ch, hid_ch)\n",
        "        self.lin   = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class GCNDiff(GCNMean):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__(in_ch, hid_ch, num_cls, dropout)\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "class SAGEMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1   = SAGEConv(in_ch, hid_ch)\n",
        "        self.conv2   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.conv3   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.lin     = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class SAGEDiff(SAGEMean):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__(in_ch, hid_ch, num_cls, dropout)\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "# 3) Restore the mapping\n",
        "VariantCls = {\n",
        "    \"GCNMean\":  GCNMean,\n",
        "    \"GCNDiff\":  GCNDiff,\n",
        "    \"SAGEMean\": SAGEMean,\n",
        "    \"SAGEDiff\": SAGEDiff\n",
        "}\n",
        "\n",
        "# 4) Ensure your get_scores_with_U and FingerprintNetMLP are also defined\n",
        "# (re-run their definitions if needed)\n",
        "\n",
        "print(\"VariantCls restored. You can now rerun the baseline comparison cell.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct5sqezbJwpD",
        "outputId": "2b2205cd-212e-46e1-fae5-3c428d9197fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VariantCls restored. You can now rerun the baseline comparison cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the PROTEINS dataset splits\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "dataset = TUDataset(\n",
        "    root=\"/content/drive/MyDrive/gnnfingers/PROTEINS\",\n",
        "    name=\"PROTEINS\"\n",
        ").shuffle()\n",
        "train_dataset = dataset[:800]\n",
        "test_dataset  = dataset[800:]\n",
        "\n",
        "print(f\"Datasets restored: {len(train_dataset)} train graphs, {len(test_dataset)} test graphs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3YJRFCTJ8hT",
        "outputId": "ca628dee-d3c2-4426-9ff1-09f933f6749f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets restored: 800 train graphs, 313 test graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount drive and set device\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2) Reload PROTEINS dataset and splits\n",
        "from torch_geometric.datasets import TUDataset\n",
        "dataset = TUDataset(\n",
        "    root=\"/content/drive/MyDrive/gnnfingers/PROTEINS\",\n",
        "    name=\"PROTEINS\"\n",
        ").shuffle()\n",
        "train_dataset = dataset[:800]\n",
        "test_dataset  = dataset[800:]\n",
        "print(f\"Loaded PROTEINS: {len(train_dataset)} train, {len(test_dataset)} test graphs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_toPZ_JKGVC",
        "outputId": "1ca31f89-2087-426f-cf93-ff9f0b3c366c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cpu\n",
            "Loaded PROTEINS: 800 train, 313 test graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Complete Environment Setup ────────────────────────────────────────────────\n",
        "import os, copy, random, torch, numpy as np\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool\n",
        "from torchattacks import DeepFool\n",
        "# from ipguard import IPGuardAttack  # if available\n",
        "\n",
        "# 1) Mount & Device\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2) Dataset splits\n",
        "dataset = TUDataset(root=\"/content/drive/MyDrive/gnnfingers/PROTEINS\", name=\"PROTEINS\").shuffle()\n",
        "train_dataset = dataset[:800]\n",
        "test_dataset  = dataset[800:]\n",
        "\n",
        "# 3) Model definitions\n",
        "class GCNMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_ch, hid_ch)\n",
        "        self.conv2 = GCNConv(hid_ch, hid_ch)\n",
        "        self.conv3 = GCNConv(hid_ch, hid_ch)\n",
        "        self.lin   = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class GCNDiff(GCNMean):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__(in_ch, hid_ch, num_cls, dropout)\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "class SAGEMean(nn.Module):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1   = SAGEConv(in_ch, hid_ch)\n",
        "        self.conv2   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.conv3   = SAGEConv(hid_ch, hid_ch)\n",
        "        self.lin     = nn.Linear(hid_ch, num_cls)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(global_mean_pool(x, batch))\n",
        "\n",
        "class SAGEDiff(SAGEMean):\n",
        "    def __init__(self, in_ch, hid_ch, num_cls, dropout=0.5):\n",
        "        super().__init__(in_ch, hid_ch, num_cls, dropout)\n",
        "        self.skip_lin = nn.Linear(in_ch, hid_ch) if in_ch != hid_ch else None\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x0 = self.skip_lin(x) if self.skip_lin is not None else x\n",
        "        h1 = F.relu(self.conv1(x, edge_index)) + x0\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "        h2 = F.relu(self.conv2(h1, edge_index)) + h1\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "        h3 = F.relu(self.conv3(h2, edge_index)) + h2\n",
        "        return self.lin(global_mean_pool(h3, batch))\n",
        "\n",
        "VariantCls = {\"GCNMean\": GCNMean, \"GCNDiff\": GCNDiff, \"SAGEMean\": SAGEMean, \"SAGEDiff\": SAGEDiff}\n",
        "\n",
        "# 4) Paths & hyperparams\n",
        "victim_ckpt_dir   = \"/content/drive/MyDrive/gnnfingers/checkpoints\"\n",
        "variants_base_dir = \"/content/drive/MyDrive/gnnfingers/variants\"\n",
        "NUM_VARIANTS      = 200\n",
        "LR                = 0.005\n",
        "WD                = 1e-4\n",
        "\n",
        "# 5) Utility functions (redefine these if lost)\n",
        "# - extract_fp(model, U, graphs)\n",
        "# - FingerprintNetMLP\n",
        "# - get_scores_with_U\n",
        "# - generate_deepfool_negatives\n",
        "# - generate_ipguard_negatives\n",
        "\n",
        "print(\"✔ Environment fully restored.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "fwQJmoR2KWT6",
        "outputId": "3bafa5a2-b77f-4be1-d1ee-6f1afe33a921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchattacks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4230233707>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAGEConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepFool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# from ipguard import IPGuardAttack  # if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchattacks'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1) FingerprintNetMLP ---\n",
        "import torch.nn as nn\n",
        "class FingerprintNetMLP(nn.Module):\n",
        "    def __init__(self, embed_dim=64, key_dim=64, h1=256, h2=128, h3=64, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.key = nn.Parameter(torch.randn(key_dim), requires_grad=False)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embed_dim + key_dim, h1), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h1, h2),                nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h2, h3),                nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(h3, 2)\n",
        "        )\n",
        "    def forward(self, emb):\n",
        "        k = self.key.unsqueeze(0).expand(emb.size(0), -1).to(emb.device)\n",
        "        return self.net(torch.cat([emb, k], dim=1))\n"
      ],
      "metadata": {
        "id": "y1lVi2e4KlT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2) extract_fp ---\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "def extract_fp(model, U_net, graphs):\n",
        "    all_p = []\n",
        "    for batch in DataLoader(graphs, batch_size=32, shuffle=False):\n",
        "        b = batch.to(device)\n",
        "        x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "        x = F.dropout(x, p=model.dropout, training=False)\n",
        "        x = F.relu(model.conv2(x, b.edge_index))\n",
        "        x = F.dropout(x, p=model.dropout, training=False)\n",
        "        x = F.relu(model.conv3(x, b.edge_index))\n",
        "        all_p.append(global_mean_pool(x, b.batch))\n",
        "    pooled = torch.cat(all_p, dim=0)\n",
        "    with torch.no_grad():\n",
        "        k = U_net.key.unsqueeze(0).expand(pooled.size(0), -1).to(device)\n",
        "        h = torch.cat([pooled, k], dim=1)\n",
        "        feats = U_net.net[:-1](h)\n",
        "    return feats.mean(dim=0).cpu().numpy()\n"
      ],
      "metadata": {
        "id": "hVps28V3Km57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3) get_scores_with_U ---\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def get_scores_with_U(model, U_net, graphs):\n",
        "    scs = []\n",
        "    model.eval(); U_net.eval()\n",
        "    for batch in DataLoader(graphs, batch_size=32, shuffle=False):\n",
        "        b = batch.to(device)\n",
        "        x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "        x = F.relu(model.conv2(x, b.edge_index))\n",
        "        x = F.relu(model.conv3(x, b.edge_index))\n",
        "        pooled = global_mean_pool(x, b.batch)\n",
        "        logits = U_net(pooled)\n",
        "        scs.append(torch.softmax(logits, dim=1)[:,1].cpu().numpy())\n",
        "    return np.concatenate(scs)\n"
      ],
      "metadata": {
        "id": "t4QF2pZjKory"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores_with_U(model, U_net, graphs):\n",
        "    scs = []\n",
        "    model.eval(); U_net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in DataLoader(graphs, batch_size=32, shuffle=False):\n",
        "            b = batch.to(device)\n",
        "            x = F.relu(model.conv1(b.x, b.edge_index))\n",
        "            x = F.relu(model.conv2(x, b.edge_index))\n",
        "            x = F.relu(model.conv3(x, b.edge_index))\n",
        "            pooled = global_mean_pool(x, b.batch)\n",
        "            logits = U_net(pooled)\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
        "            scs.append(probs.detach().cpu().numpy())\n",
        "    return np.concatenate(scs)\n"
      ],
      "metadata": {
        "id": "8yJGi4owLTbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stub for IPGuardAttack when the real implementation isn't available\n",
        "def IPGuardAttack(model):\n",
        "    # No-op: in the real implementation, this would perturb model weights\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "Kreq-j3dPG4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ipguard_negatives(victim_model, train_dataset, num_variants=200):\n",
        "    negatives = []\n",
        "    for _ in range(num_variants):\n",
        "        m = copy.deepcopy(victim_model)\n",
        "        IPGuardAttack(m)       # now a harmless stub\n",
        "        negatives.append(m.state_dict())\n",
        "    print(f\"Generated {len(negatives)} IPGuard negatives\")\n",
        "    return negatives\n"
      ],
      "metadata": {
        "id": "hVK0zag9PVYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def mean_test_acc(labels, scores):\n",
        "    ts = np.linspace(0, 1, 101)\n",
        "    accs = []\n",
        "    for t in ts:\n",
        "        tpr = np.mean(scores[labels == 1] >= t)\n",
        "        tnr = np.mean(scores[labels == 0] <  t)\n",
        "        accs.append((tpr + tnr) / 2)\n",
        "    return np.mean(accs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xEmXjZj-RKV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "import random, numpy as np, torch\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n"
      ],
      "metadata": {
        "id": "dlLp93OgRNAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Methods to compare\n",
        "methods = {\n",
        "    \"GNNFingers\": None,           # will load from disk as before\n",
        "    \"DeepFool\":  generate_deepfool_negatives,\n",
        "    \"IPGuard\":   generate_ipguard_negatives\n",
        "}\n",
        "\n",
        "results = []  # will collect dicts: {\"Dataset\",\"Variant\",\"Method\",\"ARUC\",\"Acc\"}\n",
        "\n",
        "for method_name, generator in methods.items():\n",
        "    print(f\"\\n=== Method: {method_name} ===\")\n",
        "\n",
        "    for name, Cls in VariantCls.items():\n",
        "        print(f\"  Variant: {name}\")\n",
        "        # 1) Load victim\n",
        "        victim = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        victim.load_state_dict(torch.load(f\"{victim_ckpt_dir}/victim_PR_{name}.pth\", map_location=device))\n",
        "        victim.eval()\n",
        "\n",
        "        # 2) Generate negatives\n",
        "        if method_name == \"GNNFingers\":\n",
        "            # Load pre-generated negatives from disk\n",
        "            neg_states = sorted(\n",
        "                [os.path.join(variants_base_dir, f\"PR_{name}/negative\", fn)\n",
        "                 for fn in os.listdir(os.path.join(variants_base_dir, f\"PR_{name}/negative\"))\n",
        "                 if fn.endswith(\".pth\")]\n",
        "            )\n",
        "            neg_states = neg_states[:NUM_VARIANTS]\n",
        "        else:\n",
        "            # Call the appropriate generator\n",
        "            neg_states = generator(victim, train_dataset, NUM_VARIANTS)\n",
        "\n",
        "        # 3) Train U on 100 pos + 100 neg of this method\n",
        "        # 3a) Positive embeddings\n",
        "        pos_graphs = list(train_dataset[:100])\n",
        "        pos_emb = extract_fp(victim, FingerprintNetMLP().to(device), pos_graphs)\n",
        "        # 3b) Negative embeddings\n",
        "        neg_embs = []\n",
        "        for i in range(100):\n",
        "            m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "            if method_name == \"GNNFingers\":\n",
        "                m.load_state_dict(torch.load(neg_states[i], map_location=device))\n",
        "            else:\n",
        "                m.load_state_dict(neg_states[i])\n",
        "            m.eval()\n",
        "            neg_embs.append(extract_fp(m, FingerprintNetMLP().to(device), pos_graphs))\n",
        "        neg_emb = np.stack(neg_embs, axis=0)\n",
        "\n",
        "        # 3c) Prepare U’s training set\n",
        "        X_pos = np.tile(pos_emb[np.newaxis], (100,1))\n",
        "        X = np.vstack([X_pos, neg_emb])\n",
        "        y = np.array([1]*100 + [0]*100)\n",
        "        perm = np.random.permutation(200)\n",
        "        X_t = torch.tensor(X[perm], dtype=torch.float32).to(device)\n",
        "        y_t = torch.tensor(y[perm], dtype=torch.long).to(device)\n",
        "        loader_U = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(X_t, y_t),\n",
        "            batch_size=32, shuffle=True\n",
        "        )\n",
        "\n",
        "        # 3d) Train U\n",
        "        U = FingerprintNetMLP().to(device)\n",
        "        optU = torch.optim.Adam(U.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        for epoch in range(1,201):\n",
        "            U.train()\n",
        "            total, correct = 0,0\n",
        "            for xb,yb in loader_U:\n",
        "                logits = U(xb)\n",
        "                loss = loss_fn(logits, yb)\n",
        "                optU.zero_grad(); loss.backward(); optU.step()\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds==yb).sum().item()\n",
        "                total   += yb.size(0)\n",
        "            if correct/total >= 0.95:\n",
        "                break\n",
        "        U.eval()\n",
        "\n",
        "        # 4) Score on test set: positives and all negatives\n",
        "        pos_scores = get_scores_with_U(victim, U, list(test_dataset))\n",
        "        neg_scores_all = []\n",
        "        for i in range(NUM_VARIANTS):\n",
        "            m = Cls(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "            if method_name == \"GNNFingers\":\n",
        "                m.load_state_dict(torch.load(neg_states[i], map_location=device))\n",
        "            else:\n",
        "                m.load_state_dict(neg_states[i])\n",
        "            m.eval()\n",
        "            neg_scores_all.append(get_scores_with_U(m, U, list(test_dataset)))\n",
        "        neg_flat = np.concatenate(neg_scores_all)\n",
        "\n",
        "        # 5) Compute metrics\n",
        "        labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_flat)])\n",
        "        scores = np.concatenate([pos_scores, neg_flat])\n",
        "        aruc = roc_auc_score(labels, scores)\n",
        "        acc = mean_test_acc(\n",
        "            np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_flat)]),\n",
        "            np.concatenate([pos_scores,neg_flat]))\n",
        "\n",
        "        results.append({\n",
        "            \"Dataset\": \"PROTEINS\",\n",
        "            \"Variant\": name,\n",
        "            \"Method\":  method_name,\n",
        "            \"ARUC\":    aruc,\n",
        "            \"Acc\":     acc\n",
        "        })\n",
        "        print(f\"    {method_name}-{name} → ARUC={aruc:.3f}, Acc={acc:.3f}\")\n",
        "\n",
        "# Convert to Pandas and display\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "df_pivot = df.pivot_table(index=[\"Dataset\",\"Variant\"], columns=\"Method\", values=[\"ARUC\",\"Acc\"])\n",
        "print(df_pivot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zED54PLKJnID",
        "outputId": "a6784bf5-6432-4f1f-f2d3-d535b0e0b9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Method: GNNFingers ===\n",
            "  Variant: GCNMean\n",
            "    GNNFingers-GCNMean → ARUC=0.452, Acc=0.497\n",
            "  Variant: GCNDiff\n",
            "    GNNFingers-GCNDiff → ARUC=0.179, Acc=0.398\n",
            "  Variant: SAGEMean\n",
            "    GNNFingers-SAGEMean → ARUC=0.421, Acc=0.493\n",
            "  Variant: SAGEDiff\n",
            "    GNNFingers-SAGEDiff → ARUC=0.724, Acc=0.521\n",
            "\n",
            "=== Method: DeepFool ===\n",
            "  Variant: GCNMean\n",
            "Generated 200 DeepFool negatives\n",
            "    DeepFool-GCNMean → ARUC=0.505, Acc=0.500\n",
            "  Variant: GCNDiff\n",
            "Generated 200 DeepFool negatives\n",
            "    DeepFool-GCNDiff → ARUC=0.498, Acc=0.500\n",
            "  Variant: SAGEMean\n",
            "Generated 200 DeepFool negatives\n",
            "    DeepFool-SAGEMean → ARUC=0.496, Acc=0.500\n",
            "  Variant: SAGEDiff\n",
            "Generated 200 DeepFool negatives\n",
            "    DeepFool-SAGEDiff → ARUC=0.508, Acc=0.500\n",
            "\n",
            "=== Method: IPGuard ===\n",
            "  Variant: GCNMean\n",
            "Generated 200 IPGuard negatives\n",
            "    IPGuard-GCNMean → ARUC=0.500, Acc=0.500\n",
            "  Variant: GCNDiff\n",
            "Generated 200 IPGuard negatives\n",
            "    IPGuard-GCNDiff → ARUC=0.500, Acc=0.500\n",
            "  Variant: SAGEMean\n",
            "Generated 200 IPGuard negatives\n",
            "    IPGuard-SAGEMean → ARUC=0.500, Acc=0.500\n",
            "  Variant: SAGEDiff\n",
            "Generated 200 IPGuard negatives\n",
            "    IPGuard-SAGEDiff → ARUC=0.500, Acc=0.500\n",
            "                       ARUC                          Acc                   \n",
            "Method             DeepFool GNNFingers IPGuard  DeepFool GNNFingers IPGuard\n",
            "Dataset  Variant                                                           \n",
            "PROTEINS GCNDiff   0.498462   0.178801     0.5  0.499928   0.397823     0.5\n",
            "         GCNMean   0.505212   0.452327     0.5  0.500304   0.497437     0.5\n",
            "         SAGEDiff  0.507528   0.724303     0.5  0.500177   0.520600     0.5\n",
            "         SAGEMean  0.496412   0.420780     0.5  0.499869   0.493363     0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ablation_negatives(mode, victim, num_variants=200):\n",
        "    negatives = []\n",
        "    for vid in range(num_variants):\n",
        "        m = copy.deepcopy(victim)\n",
        "        # Freeze/unfreeze parameters:\n",
        "        for name, p in m.named_parameters():\n",
        "            if mode == \"A_only\":\n",
        "                # assume conv layers are adjacency-based; freeze their parameters\n",
        "                if \"conv\" in name:\n",
        "                    p.requires_grad = False\n",
        "            elif mode == \"X_only\":\n",
        "                # assume feature-readout linear layers handle node features; freeze others\n",
        "                if \"lin\" not in name:\n",
        "                    p.requires_grad = False\n",
        "        # Fine-tune on train_dataset for a few epochs\n",
        "        opt = torch.optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=LR, weight_decay=WD)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        for _ in range(5):  # 5 epochs as in paper\n",
        "            for batch in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
        "                batch = batch.to(device)\n",
        "                logits = m(batch.x, batch.edge_index, batch.batch)\n",
        "                loss = loss_fn(logits, batch.y.view(-1))\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "        negatives.append(m.state_dict())\n",
        "    return negatives\n"
      ],
      "metadata": {
        "id": "RU68zJ1_X27b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 1: Seeding & Hyperparameters ───\n",
        "SEED = 12345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark     = False\n",
        "\n",
        "LR        = 1e-3    # victim fine-tuning LR\n",
        "WD        = 1e-4\n",
        "INNER_E   = 5       # inner fine-tune epochs per variant\n",
        "Q         = NUM_VARIANTS\n",
        "BATCH_SZ  = 32\n",
        "U_LR      = 1e-3\n",
        "U_WD      = 1e-4\n",
        "U_EPOCHS  = 200\n",
        "EARLY_ACC = 0.95\n"
      ],
      "metadata": {
        "id": "P5R-kJw7OyKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2: Wrapper Functions ───\n",
        "def generate_ablation_states(mode, victim, num_variants=Q):\n",
        "    states = []\n",
        "    for _ in range(num_variants):\n",
        "        m = copy.deepcopy(victim)\n",
        "        # Freeze/unfreeze properly:\n",
        "        for name, p in m.named_parameters():\n",
        "            if mode == \"A_only\" and \"lin\" in name:\n",
        "                # freeze feature layer\n",
        "                p.requires_grad = False\n",
        "            if mode == \"X_only\" and \"conv\" in name:\n",
        "                # freeze adjacency layer\n",
        "                p.requires_grad = False\n",
        "\n",
        "        opt = torch.optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, m.parameters()),\n",
        "            lr=LR, weight_decay=WD\n",
        "        )\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        for _ in range(INNER_E):\n",
        "            for batch in DataLoader(train_dataset, batch_size=BATCH_SZ, shuffle=True):\n",
        "                batch = batch.to(device)\n",
        "                out = m(batch.x, batch.edge_index, batch.batch)\n",
        "                loss = loss_fn(out, batch.y.view(-1))\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "        states.append(m.state_dict())\n",
        "    return states\n",
        "\n",
        "def get_variant_states(mode, victim, Q=Q):\n",
        "    if mode == \"Both\":\n",
        "        # load the first Q checkpoints from the \"negative\" folder\n",
        "        neg_dir = os.path.join(variants_base_dir, \"PR_GCNMean\", \"negative\")\n",
        "        ckpts   = sorted(os.listdir(neg_dir))[:Q]\n",
        "        states  = [\n",
        "            torch.load(os.path.join(neg_dir, ckpt), map_location=device)\n",
        "            for ckpt in ckpts\n",
        "        ]\n",
        "        return states\n",
        "    else:\n",
        "        # A_only or X_only\n",
        "        return generate_ablation_states(mode, victim, num_variants=Q)\n",
        "\n",
        "\n",
        "def extract_graph_embeddings(states, graphs, fp_extractor):\n",
        "    embs = []\n",
        "    for st in states:\n",
        "        m = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(st); m.eval()\n",
        "        # build fresh U_net just for signature (not trained here)\n",
        "        U_net = FingerprintNetMLP().to(device)\n",
        "        emb = fp_extractor(m, U_net, graphs)  # returns (batch_size, hidden)\n",
        "        embs.append(emb.reshape(1, -1))        # flatten per-state\n",
        "    return np.vstack(embs)                    # shape (Q, hidden)\n"
      ],
      "metadata": {
        "id": "Is5Nr2G6OyAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 0: Imports, Models, Helpers, Data ───\n",
        "import os, random, copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "# 1) Three-layer GCN victim\n",
        "class GCNMean(nn.Module):\n",
        "    def __init__(self, in_feats, hidden, num_classes, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.conv3 = GCNConv(hidden, hidden)\n",
        "        self.lin   = nn.Linear(hidden, num_classes)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)\n",
        "\n",
        "# 2) U-network for classification/fingerprints\n",
        "class FingerprintNetMLP(nn.Module):\n",
        "    def __init__(self, inp_dim=64, hidden=128, out_dim=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(inp_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 3) Fingerprint extraction\n",
        "def extract_fp(victim_model, U_net, graph_list):\n",
        "    \"\"\"\n",
        "    Runs victim_model on each graph in graph_list to get per-graph embeddings,\n",
        "    then averages them into one global fingerprint vector of shape (hidden,).\n",
        "    \"\"\"\n",
        "    victim_model.eval()\n",
        "    loader = DataLoader(graph_list, batch_size=len(graph_list), shuffle=False)\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = F.relu(victim_model.conv1(batch.x, batch.edge_index))\n",
        "            x = F.dropout(x, p=victim_model.dropout, training=False)\n",
        "            x = F.relu(victim_model.conv2(x, batch.edge_index))\n",
        "            x = F.dropout(x, p=victim_model.dropout, training=False)\n",
        "            x = F.relu(victim_model.conv3(x, batch.edge_index))\n",
        "            pooled = global_mean_pool(x, batch.batch)   # (num_graphs, hidden)\n",
        "        # average across graphs → (hidden,)\n",
        "        fingerprint = pooled.mean(dim=0)\n",
        "        return fingerprint.cpu().numpy()\n",
        "\n",
        "# 4) Scoring function for ARUC\n",
        "def get_scores_with_U(model, U_net, graph_list):\n",
        "    \"\"\"\n",
        "    Computes U_net probabilities for the positive class (index=1) on model(graphs).\n",
        "    Returns a numpy array of shape (len(graph_list),).\n",
        "    \"\"\"\n",
        "    model.eval(); U_net.eval()\n",
        "    loader = DataLoader(graph_list, batch_size=len(graph_list), shuffle=False)\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            # get GCN pooled features\n",
        "            x = F.relu(model.conv1(batch.x, batch.edge_index))\n",
        "            x = F.dropout(x, p=model.dropout, training=False)\n",
        "            x = F.relu(model.conv2(x, batch.edge_index))\n",
        "            x = F.dropout(x, p=model.dropout, training=False)\n",
        "            x = F.relu(model.conv3(x, batch.edge_index))\n",
        "            pooled = global_mean_pool(x, batch.batch)\n",
        "            # U_net logits → probabilities\n",
        "            logits = U_net(pooled)\n",
        "            probs  = F.softmax(logits, dim=1)[:,1]\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "# 5) Load PROTEINS dataset & split\n",
        "dataset = TUDataset(root='data/PROTEINS', name='PROTEINS')\n",
        "num_train = int(0.8 * len(dataset))\n",
        "train_dataset = dataset[:num_train]\n",
        "test_dataset  = dataset[num_train:]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 6) Checkpoint paths\n",
        "victim_ckpt_dir   = \"/content/drive/MyDrive/gnnfingers/checkpoints\"\n",
        "variants_base_dir = \"/content/drive/MyDrive/gnnfingers/variants\"\n",
        "NUM_VARIANTS      = 200\n"
      ],
      "metadata": {
        "id": "hiITySTU_A7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: Dry-Run Sanity Check ───\n",
        "\n",
        "# 1) Reload victim\n",
        "victim = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "victim.load_state_dict(torch.load(f\"{victim_ckpt_dir}/victim_PR_GCNMean.pth\", map_location=device))\n",
        "victim.eval()\n",
        "\n",
        "# 2) Single-graph batch\n",
        "graph = train_dataset[0:1]\n",
        "\n",
        "# 3) Generate 10 ablated variants\n",
        "test_states = get_variant_states(\"A_only\", victim, Q=10)\n",
        "\n",
        "# 4) Extract negative embeddings\n",
        "neg_embs = extract_graph_embeddings(test_states, graph, extract_fp)\n",
        "print(\"neg_embs.shape:\", neg_embs.shape)  # expect (10, hidden_dim)\n",
        "\n",
        "# 5) Positive embedding\n",
        "pos_fp   = extract_fp(victim, FingerprintNetMLP().to(device), graph)\n",
        "pos_flat = pos_fp.reshape(-1)\n",
        "pos_rep  = np.tile(pos_flat, (neg_embs.shape[0], 1))\n",
        "print(\"pos_rep.shape:\", pos_rep.shape)    # expect (10, hidden_dim)\n",
        "\n",
        "# 6) Train U and report\n",
        "U_net, acc, epochs = train_U(pos_rep, neg_embs)\n",
        "print(f\"Dry-run U accuracy: {acc:.3f} after {epochs} epochs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh5hEsnM_CJJ",
        "outputId": "0fb3ab89-3a32-4ddf-b00e-0d3583b03300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neg_embs.shape: (10, 64)\n",
            "pos_rep.shape: (10, 64)\n",
            "Dry-run U accuracy: 1.000 after 4 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Full Ablation Sweep (fixed 100-graph subset) ───\n",
        "results_ablation = {}\n",
        "pos_graphs = list(train_dataset[:100])  # FIXED subset of 100 graphs\n",
        "\n",
        "for mode in [\"A_only\", \"X_only\", \"Both\"]:\n",
        "    print(f\"\\n=== Mode: {mode} ===\")\n",
        "\n",
        "    # 1) Generate or load variants\n",
        "    variants = get_variant_states(mode, victim, Q=Q)\n",
        "\n",
        "    # 2) Extract negative embeddings on the 100 graphs\n",
        "    neg_embs = extract_graph_embeddings(variants, pos_graphs, extract_fp)\n",
        "\n",
        "    # 3) Extract positive fingerprint (one vector) on the same 100 graphs\n",
        "    pos_fp   = extract_fp(victim, FingerprintNetMLP().to(device), pos_graphs)\n",
        "    pos_flat = pos_fp.reshape(-1)\n",
        "    # tile to (Q, hidden)\n",
        "    pos_rep  = np.tile(pos_flat, (Q, 1))\n",
        "\n",
        "    # 4) Train U on these 100-graph embeddings\n",
        "    U_net, train_acc, epochs_used = train_U(pos_rep, neg_embs)\n",
        "    print(f\"Trained U → acc={train_acc:.4f}, epochs={epochs_used}\")\n",
        "\n",
        "    # 5) Score positives on full test set\n",
        "    pos_scores = get_scores_with_U(victim, U_net, list(test_dataset))\n",
        "\n",
        "    # 6) Score negatives on full test set\n",
        "    neg_scores_list = []\n",
        "    for st in variants:\n",
        "        m = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(st); m.eval()\n",
        "        neg_scores_list.append(get_scores_with_U(m, U_net, list(test_dataset)))\n",
        "    neg_flat = np.concatenate(neg_scores_list)\n",
        "\n",
        "    # 7) Compute ARUC\n",
        "    labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_flat)])\n",
        "    scores = np.concatenate([pos_scores, neg_flat])\n",
        "    aruc   = roc_auc_score(labels, scores)\n",
        "    results_ablation[mode] = aruc\n",
        "    print(f\"{mode} ARUC = {aruc:.4f}\")\n",
        "\n",
        "print(\"\\nFinal A-vs-X Ablation results:\", results_ablation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiqIStqsW0S0",
        "outputId": "96597a63-9a12-4f20-de2b-93686f2c8d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Mode: A_only ===\n",
            "Trained U → acc=1.0000, epochs=5\n",
            "A_only ARUC = 0.6342\n",
            "\n",
            "=== Mode: X_only ===\n",
            "Trained U → acc=0.5000, epochs=200\n",
            "X_only ARUC = 0.5000\n",
            "\n",
            "=== Mode: Both ===\n",
            "Trained U → acc=0.9500, epochs=12\n",
            "Both ARUC = 0.6132\n",
            "\n",
            "Final A-vs-X Ablation results: {'A_only': np.float64(0.6341504956866214), 'X_only': np.float64(0.5), 'Both': np.float64(0.6131564077298961)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 0: Imports, Model Definitions, and Paths ───\n",
        "import os, random, copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics     import accuracy_score, roc_auc_score\n",
        "from torch.optim         import Adam\n",
        "from torch_geometric.datasets import TUDataset, Planetoid\n",
        "from torch_geometric.loader   import DataLoader\n",
        "from torch_geometric.nn       import GCNConv, global_mean_pool\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Victim GCN (3 layers) and Fingerprint MLP\n",
        "class GCNMean(nn.Module):\n",
        "    def __init__(self, in_feats, hidden, num_classes, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.conv3 = GCNConv(hidden, hidden)\n",
        "        self.lin   = nn.Linear(hidden, num_classes)\n",
        "        self.dropout = dropout\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)\n",
        "\n",
        "class FingerprintNetMLP(nn.Module):\n",
        "    def __init__(self, inp_dim=64, hidden=128, out_dim=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(inp_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Paths & dataset\n",
        "victim_ckpt_dir   = \"/content/drive/MyDrive/gnnfingers/checkpoints\"\n",
        "variants_base_dir = \"/content/drive/MyDrive/gnnfingers/variants\"\n",
        "NUM_VARIANTS      = 200\n",
        "\n",
        "# PROTEINS graph-dataset\n",
        "dataset = TUDataset(root='data/PROTEINS', name='PROTEINS')\n",
        "num_train   = int(0.8 * len(dataset))\n",
        "train_dataset = dataset[:num_train]\n",
        "test_dataset  = dataset[num_train:]\n"
      ],
      "metadata": {
        "id": "Ui-CiwyoDz-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 1: Seeding & Hyper-parameters ───\n",
        "SEED       = 12345\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark     = False\n",
        "\n",
        "LR        = 1e-3    # victim fine-tuning LR\n",
        "WD        = 1e-4\n",
        "INNER_E   = 5       # inner fine-tune epochs per variant\n",
        "Q         = NUM_VARIANTS\n",
        "BATCH_SZ  = 32\n",
        "U_LR      = 1e-3\n",
        "U_WD      = 1e-4\n",
        "U_EPOCHS  = 200\n",
        "EARLY_ACC = 0.95\n"
      ],
      "metadata": {
        "id": "jdobjtJrLxGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2: Core Helpers ───\n",
        "\n",
        "# 1) generate_ablation_states with correct freeze logic\n",
        "def generate_ablation_states(mode, victim, num_variants=Q):\n",
        "    states = []\n",
        "    for _ in range(num_variants):\n",
        "        m = copy.deepcopy(victim)\n",
        "        for name, p in m.named_parameters():\n",
        "            if mode == \"A_only\" and \"lin\" in name:\n",
        "                p.requires_grad = False\n",
        "            if mode == \"X_only\" and \"conv\" in name:\n",
        "                p.requires_grad = False\n",
        "        opt = Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=LR, weight_decay=WD)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        for _ in range(INNER_E):\n",
        "            for batch in DataLoader(train_dataset, batch_size=BATCH_SZ, shuffle=True):\n",
        "                batch = batch.to(device)\n",
        "                out = m(batch.x, batch.edge_index, batch.batch)\n",
        "                loss = loss_fn(out, batch.y.view(-1))\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "        states.append(m.state_dict())\n",
        "    return states\n",
        "\n",
        "# 2) get_variant_states with “Both” loading\n",
        "def get_variant_states(mode, victim, Q=Q):\n",
        "    if mode == \"Both\":\n",
        "        neg_dir = os.path.join(variants_base_dir, \"PR_GCNMean\", \"negative\")\n",
        "        ckpts   = sorted(os.listdir(neg_dir))[:Q]\n",
        "        return [torch.load(os.path.join(neg_dir, ckpt), map_location=device) for ckpt in ckpts]\n",
        "    else:\n",
        "        return generate_ablation_states(mode, victim, num_variants=Q)\n",
        "\n",
        "# 3) extract_fp: average pooled features across graphs → (hidden,)\n",
        "def extract_fp(victim_model, U_net, graph_list):\n",
        "    victim_model.eval()\n",
        "    loader = DataLoader(graph_list, batch_size=len(graph_list), shuffle=False)\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            x = F.relu(victim_model.conv1(batch.x, batch.edge_index))\n",
        "            x = F.dropout(x, p=victim_model.dropout, training=False)\n",
        "            x = F.relu(victim_model.conv2(x, batch.edge_index))\n",
        "            x = F.dropout(x, p=victim_model.dropout, training=False)\n",
        "            x = F.relu(victim_model.conv3(x, batch.edge_index))\n",
        "            pooled = global_mean_pool(x, batch.batch)        # (num_graphs, hidden)\n",
        "        fingerprint = pooled.mean(dim=0)                     # (hidden,)\n",
        "        return fingerprint.cpu().numpy()\n",
        "\n",
        "# 4) extract_graph_embeddings → (Q, hidden)\n",
        "def extract_graph_embeddings(states, graphs, fp_extractor):\n",
        "    embs = []\n",
        "    for st in states:\n",
        "        m = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(st); m.eval()\n",
        "        embs.append(fp_extractor(m, FingerprintNetMLP().to(device), graphs))\n",
        "    return np.stack(embs, axis=0)\n",
        "\n",
        "# 5) train_U on (Q×hidden) arrays\n",
        "def train_U(X_pos, X_neg, seed=SEED):\n",
        "    X  = np.vstack([X_pos, X_neg])\n",
        "    y  = np.array([1]*len(X_pos) + [0]*len(X_neg))\n",
        "    perm = np.random.RandomState(seed).permutation(len(y))\n",
        "    X_t   = torch.tensor(X[perm], dtype=torch.float32).to(device)\n",
        "    y_t   = torch.tensor(y[perm], dtype=torch.long).to(device)\n",
        "    ds    = torch.utils.data.TensorDataset(X_t, y_t)\n",
        "    loader= torch.utils.data.DataLoader(ds, batch_size=BATCH_SZ, shuffle=True)\n",
        "\n",
        "    U      = FingerprintNetMLP().to(device)\n",
        "    optU   = Adam(U.parameters(), lr=U_LR, weight_decay=U_WD)\n",
        "    loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, U_EPOCHS+1):\n",
        "        U.train(); correct = total = 0\n",
        "        for xb, yb in loader:\n",
        "            logits = U(xb); loss = loss_fn(logits, yb)\n",
        "            optU.zero_grad(); loss.backward(); optU.step()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total   += yb.size(0)\n",
        "        acc = correct/total\n",
        "        if acc >= EARLY_ACC:\n",
        "            break\n",
        "    return U, acc, epoch\n"
      ],
      "metadata": {
        "id": "qi9lSlksLzu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: Full Ablation Sweep ───\n",
        "victim = GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device)\n",
        "victim.load_state_dict(torch.load(f\"{victim_ckpt_dir}/victim_PR_GCNMean.pth\", map_location=device))\n",
        "victim.eval()\n",
        "\n",
        "results_ablation = {}\n",
        "pos_graphs = list(train_dataset[:100])  # fixed subset\n",
        "\n",
        "for mode in [\"A_only\", \"X_only\", \"Both\"]:\n",
        "    print(f\"\\n=== Mode: {mode} ===\")\n",
        "    variants  = get_variant_states(mode, victim, Q=Q)\n",
        "    neg_embs  = extract_graph_embeddings(variants, pos_graphs, extract_fp)\n",
        "    pos_fp    = extract_fp(victim, FingerprintNetMLP().to(device), pos_graphs)\n",
        "    pos_rep   = np.tile(pos_fp.reshape(-1), (Q,1))\n",
        "    U_net, tr_acc, epochs_used = train_U(pos_rep, neg_embs)\n",
        "    print(f\"Trained U → acc={tr_acc:.4f}, epochs={epochs_used}\")\n",
        "    pos_scores = get_scores_with_U(victim, U_net, list(test_dataset))\n",
        "    neg_scores = np.concatenate([\n",
        "        get_scores_with_U(\n",
        "            (lambda st: (m:=GCNMean(dataset.num_node_features,64,dataset.num_classes,0.5).to(device),\n",
        "                         m.load_state_dict(st), m.eval(), m)[3]\n",
        "            )(st),\n",
        "            U_net,\n",
        "            list(test_dataset)\n",
        "        ) for st in variants\n",
        "    ])\n",
        "    labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores)])\n",
        "    scores = np.concatenate([pos_scores, neg_scores])\n",
        "    aruc   = roc_auc_score(labels, scores)\n",
        "    print(f\"{mode} ARUC = {aruc:.4f}\")\n",
        "    results_ablation[mode] = aruc\n",
        "\n",
        "print(\"\\nFinal A-vs-X Ablation results:\", results_ablation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETALkf6ZL1aQ",
        "outputId": "6ccb6422-eacd-4cf2-f643-f591308995a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Mode: A_only ===\n",
            "Trained U → acc=1.0000, epochs=5\n",
            "A_only ARUC = 0.6237\n",
            "\n",
            "=== Mode: X_only ===\n",
            "Trained U → acc=0.4750, epochs=200\n",
            "X_only ARUC = 0.5000\n",
            "\n",
            "=== Mode: Both ===\n",
            "Trained U → acc=0.9500, epochs=10\n",
            "Both ARUC = 0.6110\n",
            "\n",
            "Final A-vs-X Ablation results: {'A_only': np.float64(0.6236646624705907), 'X_only': np.float64(0.5), 'Both': np.float64(0.6110057008988719)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell: Node Classification on Cora & Citeseer ───\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GCNMeanNC(torch.nn.Module):\n",
        "    def __init__(self, in_feats, hidden, num_classes, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.conv3 = GCNConv(hidden, hidden)\n",
        "        self.lin   = torch.nn.Linear(hidden, num_classes)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(x)\n",
        "\n",
        "def run_node_classification(name):\n",
        "    # Load dataset\n",
        "    ds   = Planetoid(root=f'data/{name}', name=name)\n",
        "    data = ds[0].to(device)\n",
        "\n",
        "    # Instantiate and train GCN\n",
        "    model = GCNMeanNC(ds.num_node_features, 64, ds.num_classes, dropout=0.5).to(device)\n",
        "    opt   = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    # Extract final hidden representations\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        h = F.relu(model.conv1(data.x, data.edge_index))\n",
        "        h = F.relu(model.conv2(h, data.edge_index))\n",
        "        h = F.relu(model.conv3(h, data.edge_index))\n",
        "        emb    = h.cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "        train_idx = data.train_mask.cpu().numpy()\n",
        "        test_idx  = data.test_mask.cpu().numpy()\n",
        "\n",
        "    # Train & evaluate logistic regression\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(emb[train_idx], labels[train_idx])\n",
        "    preds = clf.predict(emb[test_idx])\n",
        "    acc   = accuracy_score(labels[test_idx], preds)\n",
        "    print(f\"{name} node-classification accuracy: {acc:.4f}\")\n",
        "\n",
        "# Run on both datasets\n",
        "run_node_classification(\"Cora\")\n",
        "run_node_classification(\"CiteSeer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de3bYllrMFm5",
        "outputId": "72d7d02c-8a9a-439d-9aae-1d06dc327e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora node-classification accuracy: 0.7880\n",
            "CiteSeer node-classification accuracy: 0.6350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell: Link Prediction on Cora & Citeseer (CORRECTED) ───\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.metrics         import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn       import GCNConv\n",
        "from torch.optim              import Adam\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Reuse your GCNMeanNC from node classification\n",
        "class GCNMeanNC(torch.nn.Module):\n",
        "    def __init__(self, in_feats, hidden, num_classes, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_feats, hidden)\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        self.conv3 = GCNConv(hidden, hidden)\n",
        "        self.lin   = torch.nn.Linear(hidden, num_classes)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return self.lin(x)\n",
        "\n",
        "def extract_node_embeddings_planetoid(model, data):\n",
        "    \"\"\"Returns (embeddings, labels) for all nodes in data.\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = F.relu(model.conv1(data.x, data.edge_index))\n",
        "        x = F.relu(model.conv2(x, data.edge_index))\n",
        "        x = F.relu(model.conv3(x, data.edge_index))\n",
        "    return x.cpu().numpy(), data.y.cpu().numpy()\n",
        "\n",
        "def evaluate_link_prediction(name):\n",
        "    # 1) Load dataset\n",
        "    ds   = Planetoid(root=f'data/{name}', name=name)\n",
        "    data = ds[0].to(device)\n",
        "\n",
        "    # 2) Train GCN for node classification\n",
        "    model = GCNMeanNC(ds.num_node_features, 64, ds.num_classes, dropout=0.5).to(device)\n",
        "    opt   = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, 201):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    # 3) Extract per-node embeddings\n",
        "    emb, _ = extract_node_embeddings_planetoid(model, data)\n",
        "    n_nodes = emb.shape[0]\n",
        "\n",
        "    # 4) Sample positive and negative edges\n",
        "    edges = list(zip(data.edge_index[0].tolist(), data.edge_index[1].tolist()))\n",
        "    num   = min(len(edges), 1000)\n",
        "    pos   = edges[:num]\n",
        "    neg   = []\n",
        "    while len(neg) < num:\n",
        "        u, v = random.sample(range(n_nodes), 2)\n",
        "        if (u, v) not in edges and (v, u) not in edges:\n",
        "            neg.append((u, v))\n",
        "\n",
        "    # 5) Build feature pairs & labels\n",
        "    X = np.vstack([np.hstack([emb[u], emb[v]]) for u,v in pos+neg])\n",
        "    y = np.array([1]*num + [0]*num)\n",
        "\n",
        "    # 6) Split, train logistic regression, and evaluate ROC-AUC\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "    clf = LogisticRegression(max_iter=1000).fit(X_tr, y_tr)\n",
        "    auc = roc_auc_score(y_te, clf.predict_proba(X_te)[:,1])\n",
        "    print(f\"{name} link-prediction ROC-AUC: {auc:.4f}\")\n",
        "\n",
        "# Run for both datasets\n",
        "evaluate_link_prediction(\"Cora\")\n",
        "evaluate_link_prediction(\"CiteSeer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEWTyfJYPApV",
        "outputId": "56171182-ba80-4b0d-e896-ee42280a4af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora link-prediction ROC-AUC: 0.8125\n",
            "CiteSeer link-prediction ROC-AUC: 0.7547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Fixed Cell: Graph Matching on AIDS & LINUX ───\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.linear_model     import LogisticRegression\n",
        "from sklearn.metrics          import accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch.optim               import Adam\n",
        "from torch_geometric.datasets  import TUDataset\n",
        "from torch_geometric.loader    import DataLoader\n",
        "import torch.nn.functional     as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_graph_classifier(ds):\n",
        "    model = GCNMean(\n",
        "        in_feats=ds.num_node_features,\n",
        "        hidden=64,\n",
        "        num_classes=ds.num_classes,\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "    opt = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loader = DataLoader(ds[:int(0.8*len(ds))], batch_size=32, shuffle=True)\n",
        "    for epoch in range(1, 51):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            total_loss += loss_fn(out, batch.y).item()\n",
        "            loss_fn(out, batch.y).backward()\n",
        "            opt.step()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"{ds.name} Epoch {epoch:02d}, loss={total_loss/len(loader):.4f}\")\n",
        "    return model\n",
        "\n",
        "def evaluate_graph_matching(name):\n",
        "    # 1) Load & split dataset\n",
        "    ds = TUDataset(root=f'data/{name}', name=name)\n",
        "    n_train = int(0.8 * len(ds))\n",
        "    train_ds = ds[:n_train]\n",
        "    test_ds  = ds[n_train:]\n",
        "    pos_graphs = list(train_ds[:100])\n",
        "\n",
        "    # 2) Train victim on this dataset\n",
        "    print(f\"\\nTraining GCN on {name}...\")\n",
        "    victim = train_graph_classifier(ds)\n",
        "    victim.eval()\n",
        "\n",
        "    # 3) Locally fine-tune “Both” variants on train_ds\n",
        "    def generate_ablation_states_ds(victim_model, train_split, Q):\n",
        "        states = []\n",
        "        for _ in range(Q):\n",
        "            m = copy.deepcopy(victim_model)\n",
        "            # no freezing → fine-tune both A and X\n",
        "            opt = Adam(m.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loader = DataLoader(train_split, batch_size=32, shuffle=True)\n",
        "            for _ in range(5):                  # 5 inner epochs as paper\n",
        "                for batch in loader:\n",
        "                    batch = batch.to(device)\n",
        "                    opt.zero_grad()\n",
        "                    out = m(batch.x, batch.edge_index, batch.batch)\n",
        "                    loss = loss_fn(out, batch.y)\n",
        "                    loss.backward(); opt.step()\n",
        "            states.append(m.state_dict())\n",
        "        return states\n",
        "\n",
        "    variants = generate_ablation_states_ds(victim, train_ds, Q)\n",
        "\n",
        "    # 4) Extract original fingerprint\n",
        "    orig_fp = extract_fp(victim, FingerprintNetMLP().to(device), pos_graphs)\n",
        "\n",
        "    # 5) Extract each variant’s fingerprint\n",
        "    var_fps = []\n",
        "    for st in variants:\n",
        "        m = GCNMean(ds.num_node_features,64,ds.num_classes,0.5).to(device)\n",
        "        m.load_state_dict(st); m.eval()\n",
        "        var_fps.append(extract_fp(m, FingerprintNetMLP().to(device), pos_graphs))\n",
        "\n",
        "    # 6) Build pos/neg pairs\n",
        "    pos_pairs = [(orig_fp, v) for v in var_fps]\n",
        "    neg_pairs = []\n",
        "    while len(neg_pairs) < Q:\n",
        "        i, j = random.sample(range(Q), 2)\n",
        "        neg_pairs.append((var_fps[i], var_fps[j]))\n",
        "\n",
        "    # 7) Compute cosine similarities & labels\n",
        "    sims = [cosine_similarity(a.reshape(1,-1), b.reshape(1,-1))[0,0]\n",
        "            for a,b in pos_pairs+neg_pairs]\n",
        "    X = np.array(sims).reshape(-1,1)\n",
        "    y = np.array([1]*Q + [0]*Q)\n",
        "\n",
        "    # 8) Train/test split & evaluate\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "    clf = LogisticRegression(max_iter=1000).fit(X_tr, y_tr)\n",
        "    acc = accuracy_score(y_te, clf.predict(X_te))\n",
        "    print(f\"{name} graph‐matching accuracy: {acc:.4f}\")\n",
        "\n",
        "# Run it\n",
        "evaluate_graph_matching(\"AIDS\")\n",
        "evaluate_graph_matching(\"LINUX\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "0kvtyPloPlqL",
        "outputId": "779820da-ca4e-42ca-8410-0ba74761f8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GCN on AIDS...\n",
            "AIDS Epoch 10, loss=0.4385\n",
            "AIDS Epoch 20, loss=0.4286\n",
            "AIDS Epoch 30, loss=0.4169\n",
            "AIDS Epoch 40, loss=0.4108\n",
            "AIDS Epoch 50, loss=0.4075\n",
            "AIDS graph‐matching accuracy: 0.4750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/LINUX.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "https://www.chrsmrrs.com/graphkerneldatasets/LINUX.zip",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-3059485162>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mevaluate_graph_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AIDS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mevaluate_graph_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LINUX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-3059485162>\u001b[0m in \u001b[0;36mevaluate_graph_matching\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_graph_matching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# 1) Load & split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTUDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'data/{name}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/datasets/tu_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, name, transform, pre_transform, pre_filter, force_reload, use_node_attr, use_edge_attr, cleaned)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         super().__init__(root, transform, pre_transform, pre_filter,\n\u001b[0m\u001b[1;32m    130\u001b[0m                          force_reload=force_reload)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ) -> None:\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(root, transform, pre_transform, pre_filter, log,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          force_reload)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_download\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/datasets/tu_dataset.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaned_url\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleaned\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{url}/{self.name}.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py\u001b[0m in \u001b[0;36mcp\u001b[0;34m(path1, path2, extract, log, use_cache, clear_cache)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# Perform the copy:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mopen_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen_file\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmultiple_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36mopen_files\u001b[0;34m(urlpath, mode, compression, encoding, errors, name_function, num, protocol, newline, auto_mkdir, expand, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadthedocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;31m#other-known-implementations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \"\"\"\n\u001b[0;32m--> 295\u001b[0;31m     fs, fs_token, paths = get_fs_token_paths(\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0murlpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0minkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fo\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         pchains = [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/registry.py\u001b[0m in \u001b[0;36mfilesystem\u001b[0;34m(protocol, **storage_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Setting _fs_token here causes some static linters to complain.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fs_token_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/zip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fo, mode, target_protocol, target_options, compression, allowZip64, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_zip_64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the whole instance is a context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         self.zip = zipfile.ZipFile(\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/cached.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# all the methods defined in this class. Note `open` here, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# it calls `_open`, but is actually in superclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             return lambda *args, **kw: getattr(type(self), item).__get__(self)(\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1311\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/cached.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# all the methods defined in this class. Note `open` here, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# it calls `_open`, but is actually in superclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             return lambda *args, **kw: getattr(type(self), item).__get__(self)(\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/cached.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[1;32m    881\u001b[0m                     \u001b[0mf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFSTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/http.py\u001b[0m in \u001b[0;36m_get_file\u001b[0;34m(self, rpath, lpath, chunk_size, callback, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_not_found_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misfilelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/http.py\u001b[0m in \u001b[0;36m_raise_not_found_for_status\u001b[0;34m(self, response, url)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \"\"\"\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: https://www.chrsmrrs.com/graphkerneldatasets/LINUX.zip"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install advertorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EREfW73SrdI",
        "outputId": "a5b02b0a-9cfd-4580-90ac-26a9fffa2edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting advertorch\n",
            "  Downloading advertorch-0.2.3.tar.gz (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: advertorch\n",
            "  Building wheel for advertorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for advertorch: filename=advertorch-0.2.3-py3-none-any.whl size=5696198 sha256=35cf0377a4acbec7315bbcf71a453af77978e5f27feebd0d2b45f988cfc84a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/87/f6/42a80142f790e208eb27fb50ad8a5be2c31dcd3cff1c9a3a16\n",
            "Successfully built advertorch\n",
            "Installing collected packages: advertorch\n",
            "Successfully installed advertorch-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install foolbox\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGNOREimS5io",
        "outputId": "0206206d-c5ee-407f-a138-7bde79234cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox) (75.2.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox) (4.14.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
            "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import foolbox as fb\n",
        "import torch\n",
        "\n",
        "# Wrap your PyTorch model\n",
        "fmodel = fb.PyTorchModel(model, bounds=(data.x.min().item(), data.x.max().item()))\n",
        "\n",
        "# Select 64 test nodes and build per-node inputs\n",
        "test_idx = data.test_mask.nonzero().view(-1)\n",
        "sel_nodes = test_idx[torch.randperm(len(test_idx))[:64]]\n",
        "\n",
        "# We'll attack the entire feature matrix but only track perturbations at sel_nodes\n",
        "raw, clipped, is_adv = fb.attacks.deeplabel.deeplabel_deepfool(\n",
        "    fmodel, data.x, data.edge_index, epsilons=None\n",
        ")\n",
        "\n",
        "# raw is the adversarial features; extract them\n",
        "x_adv = clipped\n",
        "\n",
        "# Proceed as before: forward through GCN to get h_adv, build emb_adv, neg_sel, etc.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2q6eUUW-S8qA",
        "outputId": "abd85efa-9cd7-4da2-ca59-9ffa41981cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-3909511333>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Wrap your PyTorch model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Select 64 test nodes and build per-node inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── DeepFool Baseline: Node Classification (Cora) ───\n",
        "from advertorch.attacks import DeepFoolAttack\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 1) Load & train GCN (reuse your GCNMeanNC training code)\n",
        "ds   = Planetoid(root='data/Cora', name='Cora')\n",
        "data = ds[0].to(device)\n",
        "model = GCNMeanNC(ds.num_node_features, 64, ds.num_classes, dropout=0.5).to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "for epoch in range(1,201):\n",
        "    model.train(); opt.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward(); opt.step()\n",
        "\n",
        "# 2) Set up DeepFool\n",
        "attack = DeepFoolAttack(model, num_classes=ds.num_classes, overshoot=0.02, max_iter=50)\n",
        "\n",
        "# 3) Select 64 test nodes\n",
        "test_idx = data.test_mask.nonzero().view(-1).tolist()\n",
        "sel_nodes = random.sample(test_idx, 64)\n",
        "\n",
        "# 4) Generate adversarial examples for the entire feature matrix,\n",
        "#    but only use the perturbed feature for each selected node.\n",
        "model.eval()\n",
        "x_adv = attack.perturb(data.x, data.edge_index)  # shape (N, feat_dim)\n",
        "\n",
        "# 5) Extract embeddings: perturbed for sel_nodes, original for negatives\n",
        "with torch.no_grad():\n",
        "    h = F.relu(model.conv1(x_adv.to(device), data.edge_index))\n",
        "    h = F.relu(model.conv2(h, data.edge_index))\n",
        "    h = F.relu(model.conv3(h, data.edge_index))\n",
        "    emb_all = h.cpu().numpy()  # (N, hidden_dim)\n",
        "\n",
        "# 6) Build positive (adv) vs. negative (orig) sets\n",
        "emb_adv = emb_all[sel_nodes]                        # (64, hidden)\n",
        "neg_candidates = [n for n in test_idx if n not in sel_nodes]\n",
        "neg_sel = random.sample(neg_candidates, 64)\n",
        "emb_neg = emb_all[neg_sel]\n",
        "\n",
        "# 7) Train a simple classifier\n",
        "X = np.vstack([emb_adv, emb_neg])\n",
        "y = np.array([1]*64 + [0]*64)\n",
        "perm = np.random.permutation(128)\n",
        "X_t, y_t = X[perm], y[perm]\n",
        "clf = LogisticRegression(max_iter=1000).fit(X_t, y_t)\n",
        "acc_df = accuracy_score(y_t, clf.predict(X_t))\n",
        "print(f\"DeepFool node‐classification fingerprint accuracy (train): {acc_df:.4f}\")\n",
        "\n",
        "# 8) Evaluate on a held-out split if desired, or cross‐val for robustness.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "bjV85f3ASvNw",
        "outputId": "483785fc-2566-4e4c-99ea-58f2cb53bee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'zero_gradients' from 'torch.autograd.gradcheck' (/usr/local/lib/python3.11/dist-packages/torch/autograd/gradcheck.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1212835358>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ─── DeepFool Baseline: Node Classification (Cora) ───\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0madvertorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepFoolAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/advertorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattacks\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefenses\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/advertorch/attacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspsa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinfSPSAAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfast_adaptive_boundary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFABAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfast_adaptive_boundary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinfFABAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfast_adaptive_boundary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mL2FABAttack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/advertorch/attacks/fast_adaptive_boundary.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzero_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'zero_gradients' from 'torch.autograd.gradcheck' (/usr/local/lib/python3.11/dist-packages/torch/autograd/gradcheck.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── DeepFool Baseline: Node Classification (Cora) ───\n",
        "import deepfool  # e.g. from a library like foolbox or advertorch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "# 1) Load & train GCN on Cora (reuse model_cora from before)\n",
        "#    model_cora is already in memory if you ran the node‐classification cell.\n",
        "\n",
        "# 2) Pick 64 test nodes\n",
        "data = dataset_cora[0].to(device)\n",
        "test_idx = data.test_mask.nonzero().view(-1).tolist()\n",
        "sel_nodes = random.sample(test_idx, 64)\n",
        "\n",
        "# 3) Run DeepFool to get adversarial features for each selected node\n",
        "adv_feats = []\n",
        "for n in sel_nodes:\n",
        "    x_adv = deepfool.attack(model_cora, data.x, data.edge_index, target_node=n)\n",
        "    adv_feats.append(x_adv[n].cpu().numpy())\n",
        "adv_feats = np.stack(adv_feats, axis=0)  # shape (64, feat_dim)\n",
        "\n",
        "# 4) Extract hidden embeddings of adv feats\n",
        "model_cora.eval()\n",
        "with torch.no_grad():\n",
        "    # replace data.x[n] with adv_feats[n] in a copy of x\n",
        "    emb_adv = []\n",
        "    for i,n in enumerate(sel_nodes):\n",
        "        x_tmp = data.x.clone()\n",
        "        x_tmp[n] = torch.from_numpy(adv_feats[i]).to(device)\n",
        "        h = F.relu(model_cora.conv1(x_tmp, data.edge_index))\n",
        "        h = F.relu(model_cora.conv2(h, data.edge_index))\n",
        "        h = F.relu(model_cora.conv3(h, data.edge_index))\n",
        "        emb_adv.append(h[n].cpu().numpy())\n",
        "    emb_adv = np.stack(emb_adv, axis=0)  # (64, hidden_dim)\n",
        "\n",
        "# 5) Sample 64 other test nodes as negatives\n",
        "neg_nodes = [n for n in test_idx if n not in sel_nodes]\n",
        "neg_sel = random.sample(neg_nodes, 64)\n",
        "emb_neg = emb[neg_sel]  # emb from original extract\n",
        "\n",
        "# 6) Train U (or logistic) to distinguish emb_adv vs. emb_neg\n",
        "X = np.vstack([emb_adv, emb_neg])\n",
        "y = np.array([1]*64 + [0]*64)\n",
        "perm = np.random.permutation(128)\n",
        "X_t, y_t = X[perm], y[perm]\n",
        "clf = LogisticRegression(max_iter=1000).fit(X_t, y_t)\n",
        "acc_df = clf.score(emb[neg_sel], y[perm][perm>=64])  # compute accuracy on held-out split\n",
        "print(f\"DeepFool node‐classification fingerprint accuracy: {acc_df:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "4Dt64JYjSgSv",
        "outputId": "b349e7a0-af40-485a-d942-8d613c2b06eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deepfool'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-3418661750>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ─── DeepFool Baseline: Node Classification (Cora) ───\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdeepfool\u001b[0m  \u001b[0;31m# e.g. from a library like foolbox or advertorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1) Load & train GCN on Cora (reuse model_cora from before)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepfool'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}